{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "broken-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn import datasets\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-smith",
   "metadata": {},
   "source": [
    "### The Perceptron\n",
    "\n",
    "$$\\mathrm{heaviside}(z) = \\left\\{\\begin{matrix}\n",
    "0\\ \\mathrm{if\\ } z < 0\n",
    "\\\\ 1\\ \\mathrm{if\\ } z \\geq  0\n",
    "\\end{matrix}\\right.\\ \\mathrm{sgn}(z) = \\left\\{\\begin{matrix}\n",
    "-1\\ \\mathrm{if\\ } z < 0\n",
    "\\\\ 0\\ \\mathrm{if\\ } z = 0\n",
    "\\\\ +1\\ \\mathrm{if\\ } z >  0\n",
    "\\end{matrix}\\right.$$\n",
    "\n",
    "$$ h_{\\mathbf{W}, \\mathbf{b}}(\\mathbf{X}) = \\phi(\\mathbf{XW} + \\mathbf{b}) $$\n",
    "\n",
    "$$ w_{i, j}^{\\mathrm{(next\\ step)}} = w_{i, j} + \\eta (y_{j} - \\widehat{y}_{j})x_{i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mexican-stability",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vocal-article",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data'][:, (2, 3)] # petal length, petal width\n",
    "y = (iris.target == 0).astype(int) # iris setosa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dedicated-firewall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_clf = Perceptron()\n",
    "per_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "roman-dependence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = per_clf.predict([[2, 0.5]])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-advisory",
   "metadata": {},
   "source": [
    "### Installing Tensorflow 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "absent-savings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "surrounded-terror",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-battlefield",
   "metadata": {},
   "source": [
    "### Using Keras to load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cardiac-notice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 2us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 39s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 7s 1us/step\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "egyptian-liverpool",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "centered-project",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accomplished-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cardiac-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trousers\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \n",
    "               \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "mature-venice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "corporate-discharge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(X_valid[0], cmap=plt.cm.binary)\n",
    "plt.title(class_names[y_valid[0]])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-money",
   "metadata": {},
   "source": [
    "### Creating the model using the sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "atomic-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "civic-stroke",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "reserved-termination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "collected-pregnancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x151351d60>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x151351a30>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1513519d0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x1510a0550>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "creative-cylinder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_3'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cathedral-cartridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense_3') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "finite-wholesale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07189856, -0.01800224, -0.04418283, ...,  0.0051268 ,\n",
       "        -0.04627178, -0.06185576],\n",
       "       [-0.04330121,  0.03596477,  0.02859319, ...,  0.04854272,\n",
       "         0.05813622,  0.04829299],\n",
       "       [ 0.03017718, -0.045347  , -0.04653372, ...,  0.05969423,\n",
       "        -0.03553953,  0.02003734],\n",
       "       ...,\n",
       "       [-0.04981896, -0.02601535,  0.0274632 , ...,  0.01594956,\n",
       "        -0.02142775, -0.00517814],\n",
       "       [-0.04120284,  0.07250684,  0.04440793, ..., -0.00984857,\n",
       "         0.03706438, -0.02040084],\n",
       "       [-0.07058834, -0.03927016, -0.06519537, ..., -0.01874936,\n",
       "        -0.06153826,  0.07016808]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "smooth-strike",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "commercial-beverage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "genetic-transcription",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-brooks",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "moving-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-prophet",
   "metadata": {},
   "source": [
    "### Training and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "short-morgan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.9791 - accuracy: 0.6879 - val_loss: 0.5160 - val_accuracy: 0.8254\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.5027 - accuracy: 0.8247 - val_loss: 0.4644 - val_accuracy: 0.8382\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4510 - accuracy: 0.8433 - val_loss: 0.4349 - val_accuracy: 0.8472\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4164 - accuracy: 0.8544 - val_loss: 0.4049 - val_accuracy: 0.8596\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4019 - accuracy: 0.8582 - val_loss: 0.3991 - val_accuracy: 0.8642\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3811 - accuracy: 0.8654 - val_loss: 0.3769 - val_accuracy: 0.8688\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3724 - accuracy: 0.8694 - val_loss: 0.3627 - val_accuracy: 0.8734\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3619 - accuracy: 0.8734 - val_loss: 0.3528 - val_accuracy: 0.8742\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3505 - accuracy: 0.8754 - val_loss: 0.3484 - val_accuracy: 0.8802\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3382 - accuracy: 0.8818 - val_loss: 0.3617 - val_accuracy: 0.8682\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3263 - accuracy: 0.8835 - val_loss: 0.3332 - val_accuracy: 0.8794\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3231 - accuracy: 0.8862 - val_loss: 0.3329 - val_accuracy: 0.8794\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3142 - accuracy: 0.8879 - val_loss: 0.3275 - val_accuracy: 0.8806\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3083 - accuracy: 0.8904 - val_loss: 0.3389 - val_accuracy: 0.8784\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.3060 - accuracy: 0.8905 - val_loss: 0.3247 - val_accuracy: 0.8822\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2917 - accuracy: 0.8951 - val_loss: 0.3201 - val_accuracy: 0.8856\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2860 - accuracy: 0.8991 - val_loss: 0.3169 - val_accuracy: 0.8824\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2845 - accuracy: 0.8995 - val_loss: 0.3197 - val_accuracy: 0.8838\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2810 - accuracy: 0.8993 - val_loss: 0.3127 - val_accuracy: 0.8866\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2707 - accuracy: 0.9020 - val_loss: 0.3080 - val_accuracy: 0.8914\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2675 - accuracy: 0.9029 - val_loss: 0.3098 - val_accuracy: 0.8880\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2636 - accuracy: 0.9041 - val_loss: 0.3298 - val_accuracy: 0.8786\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2578 - accuracy: 0.9081 - val_loss: 0.3072 - val_accuracy: 0.8914\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2535 - accuracy: 0.9101 - val_loss: 0.3022 - val_accuracy: 0.8918\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2450 - accuracy: 0.9110 - val_loss: 0.3240 - val_accuracy: 0.8836\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2468 - accuracy: 0.9111 - val_loss: 0.2955 - val_accuracy: 0.8962\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2403 - accuracy: 0.9156 - val_loss: 0.3078 - val_accuracy: 0.8926\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2351 - accuracy: 0.9168 - val_loss: 0.3084 - val_accuracy: 0.8884\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2327 - accuracy: 0.9169 - val_loss: 0.3064 - val_accuracy: 0.8928\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2309 - accuracy: 0.9162 - val_loss: 0.2903 - val_accuracy: 0.8948\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "oriented-studio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dying-terror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2263 - accuracy: 0.9195 - val_loss: 0.2957 - val_accuracy: 0.8968\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2230 - accuracy: 0.9199 - val_loss: 0.2968 - val_accuracy: 0.8902\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2190 - accuracy: 0.9216 - val_loss: 0.3145 - val_accuracy: 0.8868\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2153 - accuracy: 0.9226 - val_loss: 0.2979 - val_accuracy: 0.8948\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2128 - accuracy: 0.9239 - val_loss: 0.3000 - val_accuracy: 0.8938\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2096 - accuracy: 0.9249 - val_loss: 0.2920 - val_accuracy: 0.8906\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2063 - accuracy: 0.9262 - val_loss: 0.3007 - val_accuracy: 0.8896\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2031 - accuracy: 0.9274 - val_loss: 0.2925 - val_accuracy: 0.8970\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.2000 - accuracy: 0.9291 - val_loss: 0.2955 - val_accuracy: 0.8926\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1967 - accuracy: 0.9291 - val_loss: 0.3045 - val_accuracy: 0.8886\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1940 - accuracy: 0.9311 - val_loss: 0.3090 - val_accuracy: 0.8892\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1907 - accuracy: 0.9323 - val_loss: 0.2885 - val_accuracy: 0.8942\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1869 - accuracy: 0.9335 - val_loss: 0.3040 - val_accuracy: 0.8898\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1851 - accuracy: 0.9339 - val_loss: 0.3117 - val_accuracy: 0.8894\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1807 - accuracy: 0.9359 - val_loss: 0.2937 - val_accuracy: 0.8942\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.1794 - accuracy: 0.9365 - val_loss: 0.3057 - val_accuracy: 0.8916\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1757 - accuracy: 0.9377 - val_loss: 0.2863 - val_accuracy: 0.8992\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.1736 - accuracy: 0.9385 - val_loss: 0.3030 - val_accuracy: 0.8962\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1707 - accuracy: 0.9396 - val_loss: 0.3049 - val_accuracy: 0.8890\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1678 - accuracy: 0.9402 - val_loss: 0.3017 - val_accuracy: 0.8972\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1661 - accuracy: 0.9411 - val_loss: 0.2969 - val_accuracy: 0.8966\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1627 - accuracy: 0.9421 - val_loss: 0.3072 - val_accuracy: 0.8922\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1608 - accuracy: 0.9425 - val_loss: 0.3076 - val_accuracy: 0.8954\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1568 - accuracy: 0.9448 - val_loss: 0.2921 - val_accuracy: 0.8950\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1547 - accuracy: 0.9450 - val_loss: 0.3030 - val_accuracy: 0.8930\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1517 - accuracy: 0.9464 - val_loss: 0.3217 - val_accuracy: 0.8868\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1504 - accuracy: 0.9468 - val_loss: 0.3592 - val_accuracy: 0.8794\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1475 - accuracy: 0.9478 - val_loss: 0.3086 - val_accuracy: 0.8970\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1457 - accuracy: 0.9488 - val_loss: 0.3169 - val_accuracy: 0.8932\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1433 - accuracy: 0.9495 - val_loss: 0.3136 - val_accuracy: 0.8938\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(X_train, y_train, epochs=30, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "western-andrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history2.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "polyphonic-layer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 69.8449 - accuracy: 0.8558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[69.8448715209961, 0.8557999730110168]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-partnership",
   "metadata": {},
   "source": [
    "### Using the model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "american-cloud",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "surprising-alias",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "understanding-ghost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle Boot', 'Pullover', 'Trousers'], dtype='<U11')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "wanted-budapest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "stylish-positive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.imshow(X_new[i], cmap=plt.cm.binary)\n",
    "    plt.title(class_names[y_new[i]])\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-format",
   "metadata": {},
   "source": [
    "### Building a Regression MLP Using the Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "detailed-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = datasets.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "auburn-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "accomplished-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "arbitrary-luxembourg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.4506 - val_loss: 1.2912\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6594 - val_loss: 0.5041\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4756 - val_loss: 0.4765\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4598 - val_loss: 0.4632\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4230 - val_loss: 0.4560\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4511\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.4423\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4247 - val_loss: 0.4384\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4131 - val_loss: 0.4336\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4034 - val_loss: 0.4270\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4084 - val_loss: 0.4256\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4196\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3972 - val_loss: 0.4240\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4354 - val_loss: 0.4122\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3990 - val_loss: 0.4102\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3961 - val_loss: 0.4096\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3903 - val_loss: 0.4097\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3780 - val_loss: 0.4073\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3849 - val_loss: 0.4058\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3931 - val_loss: 0.4025\n",
      "162/162 [==============================] - 0s 871us/step - loss: 0.3809\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mses_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "sacred-hunter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38088470697402954"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "celtic-turner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8473681],\n",
       "       [1.0753824],\n",
       "       [5.7369184]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "designing-while",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.562  , 0.922  , 5.00001])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-dancing",
   "metadata": {},
   "source": [
    "### Building Complex Models Using the Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "flying-enzyme",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "equipped-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5],name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6],name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fantastic-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "moved-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fifty-acrylic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.5646 - val_loss: 0.9842\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.9090 - val_loss: 0.7770\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7369 - val_loss: 0.7116\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6666 - val_loss: 0.6744\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6354 - val_loss: 0.6459\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6361 - val_loss: 0.6235\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5795 - val_loss: 0.6064\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5968 - val_loss: 0.5934\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5698 - val_loss: 0.5879\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5514 - val_loss: 0.5712\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5325 - val_loss: 0.5633\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5343 - val_loss: 0.5582\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5219 - val_loss: 0.5532\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5155 - val_loss: 0.5485\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5171 - val_loss: 0.5455\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5188 - val_loss: 0.5480\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5280 - val_loss: 0.5390\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5070 - val_loss: 0.5410\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4901 - val_loss: 0.5348\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5106 - val_loss: 0.5317\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20, validation_data=((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "following-rwanda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.5106\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "accomplished-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "danish-simple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6755316 ],\n",
       "       [0.47776085],\n",
       "       [6.335147  ]], dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "conservative-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5],name='wide_input')\n",
    "input_B = keras.layers.Input(shape=[6],name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, activation='relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation='relu')(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='main_output')(concat)\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "personal-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "hollywood-booking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 1.2482 - main_output_loss: 1.0693 - aux_output_loss: 2.8591 - val_loss: 0.6033 - val_main_output_loss: 0.5331 - val_aux_output_loss: 1.2346\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6330 - main_output_loss: 0.5731 - aux_output_loss: 1.1720 - val_loss: 0.5553 - val_main_output_loss: 0.5019 - val_aux_output_loss: 1.0367\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5299 - main_output_loss: 0.4804 - aux_output_loss: 0.9757 - val_loss: 0.5252 - val_main_output_loss: 0.4860 - val_aux_output_loss: 0.8780\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4888 - main_output_loss: 0.4512 - aux_output_loss: 0.8274 - val_loss: 0.5041 - val_main_output_loss: 0.4729 - val_aux_output_loss: 0.7852\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4709 - main_output_loss: 0.4397 - aux_output_loss: 0.7518 - val_loss: 0.4968 - val_main_output_loss: 0.4710 - val_aux_output_loss: 0.7291\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4514 - main_output_loss: 0.4256 - aux_output_loss: 0.6833 - val_loss: 0.4941 - val_main_output_loss: 0.4724 - val_aux_output_loss: 0.6895\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4492 - main_output_loss: 0.4262 - aux_output_loss: 0.6558 - val_loss: 0.4735 - val_main_output_loss: 0.4507 - val_aux_output_loss: 0.6792\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4463 - main_output_loss: 0.4229 - aux_output_loss: 0.6570 - val_loss: 0.4649 - val_main_output_loss: 0.4448 - val_aux_output_loss: 0.6456\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4316 - main_output_loss: 0.4104 - aux_output_loss: 0.6222 - val_loss: 0.4667 - val_main_output_loss: 0.4471 - val_aux_output_loss: 0.6434\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4323 - main_output_loss: 0.4134 - aux_output_loss: 0.6029 - val_loss: 0.4510 - val_main_output_loss: 0.4323 - val_aux_output_loss: 0.6197\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4122 - main_output_loss: 0.3929 - aux_output_loss: 0.5859 - val_loss: 0.4602 - val_main_output_loss: 0.4437 - val_aux_output_loss: 0.6085\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4016 - main_output_loss: 0.3829 - aux_output_loss: 0.5694 - val_loss: 0.4432 - val_main_output_loss: 0.4261 - val_aux_output_loss: 0.5966\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4137 - main_output_loss: 0.3966 - aux_output_loss: 0.5675 - val_loss: 0.4324 - val_main_output_loss: 0.4142 - val_aux_output_loss: 0.5960\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4059 - main_output_loss: 0.3881 - aux_output_loss: 0.5661 - val_loss: 0.4217 - val_main_output_loss: 0.4050 - val_aux_output_loss: 0.5721\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3915 - main_output_loss: 0.3738 - aux_output_loss: 0.5508 - val_loss: 0.4216 - val_main_output_loss: 0.4055 - val_aux_output_loss: 0.5666\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3885 - main_output_loss: 0.3709 - aux_output_loss: 0.5467 - val_loss: 0.4174 - val_main_output_loss: 0.4027 - val_aux_output_loss: 0.5499\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3790 - main_output_loss: 0.3626 - aux_output_loss: 0.5268 - val_loss: 0.4067 - val_main_output_loss: 0.3913 - val_aux_output_loss: 0.5457\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3764 - main_output_loss: 0.3601 - aux_output_loss: 0.5230 - val_loss: 0.4063 - val_main_output_loss: 0.3910 - val_aux_output_loss: 0.5433\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3855 - main_output_loss: 0.3696 - aux_output_loss: 0.5292 - val_loss: 0.4013 - val_main_output_loss: 0.3867 - val_aux_output_loss: 0.5328\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3768 - main_output_loss: 0.3610 - aux_output_loss: 0.5193 - val_loss: 0.3977 - val_main_output_loss: 0.3837 - val_aux_output_loss: 0.5238\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, \n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "solar-revision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3764 - main_output_loss: 0.3614 - aux_output_loss: 0.5107\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "brazilian-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-cornell",
   "metadata": {},
   "source": [
    "### Using the Subclassing API to Build Dynamic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "canadian-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)  # handles standard args (e.g. name)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "    \n",
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-simpson",
   "metadata": {},
   "source": [
    "### Saving and Restoring a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "recorded-fishing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.2949 - val_loss: 0.6282\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5394 - val_loss: 0.5006\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4593 - val_loss: 0.4632\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4337 - val_loss: 0.4847\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4185 - val_loss: 0.4342\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4045 - val_loss: 0.4270\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4103 - val_loss: 0.4241\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3865 - val_loss: 0.4244\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.4116\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3815 - val_loss: 0.4147\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3794 - val_loss: 0.4017\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3642 - val_loss: 0.3962\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3799 - val_loss: 0.3936\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3588 - val_loss: 0.3927\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3584 - val_loss: 0.3933\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3676 - val_loss: 0.3913\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3596 - val_loss: 0.3927\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3619 - val_loss: 0.3859\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3565 - val_loss: 0.3845\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3524 - val_loss: 0.3831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x159c49be0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "charged-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "sustained-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-probe",
   "metadata": {},
   "source": [
    "### Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bacterial-logan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3643\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3584\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3556\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3595\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.3522\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3521\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3496\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3480\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3487\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3492\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5')\n",
    "history = model.fit(X_train, y_train, epochs=10, callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "gothic-invasion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3472 - val_loss: 0.3729\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3485 - val_loss: 0.3676\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3440 - val_loss: 0.3673\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3423 - val_loss: 0.3817\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3414 - val_loss: 0.3674\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3426 - val_loss: 0.3643\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.3653\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3387 - val_loss: 0.3673\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3371 - val_loss: 0.3637\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3359 - val_loss: 0.3610\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_model.h5', save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model('my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "collaborative-brick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3405 - val_loss: 0.3595\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3439 - val_loss: 0.3703\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3374 - val_loss: 0.3627\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.3573\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3817\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3545\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.3539\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3258 - val_loss: 0.3636\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.3621\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3281 - val_loss: 0.3550\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3264 - val_loss: 0.3547\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3240 - val_loss: 0.3557\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3274 - val_loss: 0.3541\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3221 - val_loss: 0.3497\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3214 - val_loss: 0.3515\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3213 - val_loss: 0.3541\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3245 - val_loss: 0.3579\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3197 - val_loss: 0.3604\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3183 - val_loss: 0.3514\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3175 - val_loss: 0.3459\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3158 - val_loss: 0.3508\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3222 - val_loss: 0.3448\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3165 - val_loss: 0.3518\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3259 - val_loss: 0.3474\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3177 - val_loss: 0.3444\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3205 - val_loss: 0.3463\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3206 - val_loss: 0.4061\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3399 - val_loss: 0.3401\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3427 - val_loss: 0.3499\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3434 - val_loss: 0.3586\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3223 - val_loss: 0.3601\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3231 - val_loss: 0.3440\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3156 - val_loss: 0.3463\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3205 - val_loss: 0.3951\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3226 - val_loss: 0.3471\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3150 - val_loss: 0.3538\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3146 - val_loss: 0.3430\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3157 - val_loss: 0.3509\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, \n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "lesbian-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print('\\nval/train: {:.2f}'.format(logs['val_loss'] / logs['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "scenic-friend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3145 - val_loss: 0.3477\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3144 - val_loss: 0.3486\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3170 - val_loss: 0.3465\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3152 - val_loss: 0.3494\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3117 - val_loss: 0.3493\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3132 - val_loss: 0.3450\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3119 - val_loss: 0.3415\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3117 - val_loss: 0.3426\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3115 - val_loss: 0.3504\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3134 - val_loss: 0.3441\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3146 - val_loss: 0.3433\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3108 - val_loss: 0.3473\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3115 - val_loss: 0.3460\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3138 - val_loss: 0.3401\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3129 - val_loss: 0.3467\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3187 - val_loss: 0.3426\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3201 - val_loss: 0.3435\n",
      "\n",
      "val/train: 1.07\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3118 - val_loss: 0.3443\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3114 - val_loss: 0.3426\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.3403\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3083 - val_loss: 0.3417\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.3397\n",
      "\n",
      "val/train: 1.09\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3096 - val_loss: 0.3399\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3111 - val_loss: 0.3371\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3076 - val_loss: 0.3380\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3101 - val_loss: 0.3359\n",
      "\n",
      "val/train: 1.08\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3117 - val_loss: 0.3618\n",
      "\n",
      "val/train: 1.16\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3370 - val_loss: 0.3402\n",
      "\n",
      "val/train: 1.01\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3871 - val_loss: 0.3439\n",
      "\n",
      "val/train: 0.89\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3090 - val_loss: 0.3418\n",
      "\n",
      "val/train: 1.11\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3098 - val_loss: 0.3394\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3082 - val_loss: 0.3384\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3078 - val_loss: 0.3449\n",
      "\n",
      "val/train: 1.12\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3082 - val_loss: 0.3387\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3065 - val_loss: 0.3374\n",
      "\n",
      "val/train: 1.10\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3063 - val_loss: 0.3419\n",
      "\n",
      "val/train: 1.12\n"
     ]
    }
   ],
   "source": [
    "print_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=100, \n",
    "                    validation_data=(X_valid, y_valid), \n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, print_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-steam",
   "metadata": {},
   "source": [
    "### Using TensorBoard for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "vertical-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "rapid-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir():\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "hydraulic-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "entertaining-authorization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3279 - val_loss: 0.3409\n",
      "Epoch 2/32\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3089 - val_loss: 0.3558\n",
      "Epoch 3/32\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3238 - val_loss: 0.3426\n",
      "Epoch 4/32\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3168 - val_loss: 0.3425\n",
      "Epoch 5/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.3336\n",
      "Epoch 6/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3325\n",
      "Epoch 7/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.3455\n",
      "Epoch 8/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3023 - val_loss: 0.3347\n",
      "Epoch 9/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3017 - val_loss: 0.3324\n",
      "Epoch 10/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3024 - val_loss: 0.3355\n",
      "Epoch 11/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.3305\n",
      "Epoch 12/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3013 - val_loss: 0.3313\n",
      "Epoch 13/32\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3034 - val_loss: 0.3356\n",
      "Epoch 14/32\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3009 - val_loss: 0.3618\n",
      "Epoch 15/32\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3016 - val_loss: 0.3477\n",
      "Epoch 16/32\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3166 - val_loss: 0.3349\n",
      "Epoch 17/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3019 - val_loss: 0.3427\n",
      "Epoch 18/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3014 - val_loss: 0.3440\n",
      "Epoch 19/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3026 - val_loss: 0.3910\n",
      "Epoch 20/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3150 - val_loss: 0.3299\n",
      "Epoch 21/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3332\n",
      "Epoch 22/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3028 - val_loss: 0.3327\n",
      "Epoch 23/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.3301\n",
      "Epoch 24/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3018 - val_loss: 0.3348\n",
      "Epoch 25/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3092 - val_loss: 0.3326\n",
      "Epoch 26/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3079 - val_loss: 0.3760\n",
      "Epoch 27/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3030 - val_loss: 0.3320\n",
      "Epoch 28/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3093 - val_loss: 0.3328\n",
      "Epoch 29/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3015 - val_loss: 0.3395\n",
      "Epoch 30/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3043 - val_loss: 0.3414\n",
      "Epoch 31/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.3386\n",
      "Epoch 32/32\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.3300\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=32,\n",
    "                   validation_data=(X_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "controlled-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()\n",
    "writer = tf.summary.create_file_writer(test_logdir)\n",
    "with writer.as_default():\n",
    "    for step in range(1, 1000 + 1):\n",
    "        tf.summary.scalar('my_scalar', np.sin(step / 10), step=step)\n",
    "        data = (np.random.randn(100) + 2) * step / 100 # some random data\n",
    "        tf.summary.histogram('my_hist', data, buckets=50, step=step)\n",
    "        images = np.random.rand(2, 32, 32, 3) # random 32x32 RGB images\n",
    "        tf.summary.image('my_images', images * step / 1000, step=step)\n",
    "        texts = [\"The step is \" + str(step), \"Its square is \" + str(step ** 2)]\n",
    "        tf.summary.text('my_text', texts, step=step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave, tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio('my_audio', audio, sample_rate=48000, step=step)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-navigation",
   "metadata": {},
   "source": [
    "### Fine-Tuning Neural Network Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "empty-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "difficult-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "weekly-vermont",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2104 - val_loss: 0.8178\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7575 - val_loss: 0.7125\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6509 - val_loss: 0.6422\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5960 - val_loss: 0.5955\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5438 - val_loss: 0.5624\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5256 - val_loss: 0.5388\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5021 - val_loss: 0.5190\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4814 - val_loss: 0.5083\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4662 - val_loss: 0.4971\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4789 - val_loss: 0.4917\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4648 - val_loss: 0.4838\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4605 - val_loss: 0.4785\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4488 - val_loss: 0.4752\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4400 - val_loss: 0.4691\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4531 - val_loss: 0.4668\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4432 - val_loss: 0.4614\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4240 - val_loss: 0.4597\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4158 - val_loss: 0.4558\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4245 - val_loss: 0.4539\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4155 - val_loss: 0.4533\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4333 - val_loss: 0.4502\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4135 - val_loss: 0.4464\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4297 - val_loss: 0.4467\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4192 - val_loss: 0.4436\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4248 - val_loss: 0.4405\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4187 - val_loss: 0.4393\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4067 - val_loss: 0.4398\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.4356\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4018 - val_loss: 0.4341\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4091 - val_loss: 0.4338\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4081 - val_loss: 0.4331\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4084 - val_loss: 0.4305\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4168 - val_loss: 0.4311\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.4272\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.4264\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.4248\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.4231\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3960 - val_loss: 0.4243\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.4226\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3894 - val_loss: 0.4198\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3809 - val_loss: 0.4206\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3966 - val_loss: 0.4193\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3901 - val_loss: 0.4172\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3818 - val_loss: 0.4174\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4000 - val_loss: 0.4164\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3874 - val_loss: 0.4154\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3883 - val_loss: 0.4130\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3871 - val_loss: 0.4121\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3727 - val_loss: 0.4136\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3885 - val_loss: 0.4097\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3935 - val_loss: 0.4092\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3777 - val_loss: 0.4102\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3660 - val_loss: 0.4084\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3850 - val_loss: 0.4068\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.4060\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3586 - val_loss: 0.4051\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3831 - val_loss: 0.4044\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3669 - val_loss: 0.4025\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3792 - val_loss: 0.4031\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3703 - val_loss: 0.4010\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3788 - val_loss: 0.4005\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3593 - val_loss: 0.4010\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3806 - val_loss: 0.3982\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3840 - val_loss: 0.3991\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3582 - val_loss: 0.3974\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4004 - val_loss: 0.3952\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3544 - val_loss: 0.3966\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3669 - val_loss: 0.3943\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3721 - val_loss: 0.3928\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3793 - val_loss: 0.3917\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3656 - val_loss: 0.3916\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3614 - val_loss: 0.3919\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.3891\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3891\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3566 - val_loss: 0.3888\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3671 - val_loss: 0.3870\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3615 - val_loss: 0.3855\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3533 - val_loss: 0.3851\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3530 - val_loss: 0.3845\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3590 - val_loss: 0.3835\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4012 - val_loss: 0.3827\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3638 - val_loss: 0.3834\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3519 - val_loss: 0.3838\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3611 - val_loss: 0.3814\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3540 - val_loss: 0.3804\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3493 - val_loss: 0.3800\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3502 - val_loss: 0.3798\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3513 - val_loss: 0.3790\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.3786\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3470 - val_loss: 0.3767\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3459 - val_loss: 0.3762\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3498 - val_loss: 0.3765\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3531 - val_loss: 0.3761\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.3742\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3691 - val_loss: 0.3744\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3289 - val_loss: 0.3746\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3477 - val_loss: 0.3735\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3405 - val_loss: 0.3733\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3413 - val_loss: 0.3719\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3520 - val_loss: 0.3742\n",
      "162/162 [==============================] - 0s 984us/step - loss: 0.3572\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x158c45670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "incident-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "periodic-flesh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1429 - val_loss: 0.6599\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8748 - val_loss: 0.5791\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5618 - val_loss: 0.5509\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5590 - val_loss: 0.5967\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 1.0392\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6265 - val_loss: 0.5405\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5895 - val_loss: 0.5429\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5503 - val_loss: 0.5474\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5277 - val_loss: 1.1470\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6948 - val_loss: 0.5373\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6379 - val_loss: 0.5485\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5212 - val_loss: 0.5624\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5335 - val_loss: 0.5419\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5699 - val_loss: 0.5484\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5835 - val_loss: 0.5442\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 0.5469\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5659 - val_loss: 0.5404\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6156 - val_loss: 0.5356\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6752 - val_loss: 0.5352\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 0.6046 - val_loss: 0.7605\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.6148 - val_loss: 0.5398\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5233 - val_loss: 0.6184\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5550 - val_loss: 0.5388\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.5837 - val_loss: 0.5412\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5247 - val_loss: 0.6974\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5809 - val_loss: 0.5466\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6318 - val_loss: 0.5455\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6076 - val_loss: 0.5465\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5550 - val_loss: 0.7427\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.8359\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8284 - val_loss: 0.7449\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.9847 - val_loss: 3.0105\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 717.7923 - val_loss: 151.9085\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2408.6140 - val_loss: 12963.1738\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1260737.8350 - val_loss: 494668.0938\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 66057867.2137 - val_loss: 29025388.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5949087588.8889 - val_loss: 1672984704.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 286518086469.5309 - val_loss: 115381600256.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 36798434278564.3438 - val_loss: 5630742495232.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 355211075288144.0625 - val_loss: 427425649393664.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 22345018494776020.0000 - val_loss: 19322527436242944.0000\n",
      "121/121 [==============================] - 0s 981us/step - loss: 3265169928105230336.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6933 - val_loss: 0.7467\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2.9070 - val_loss: 1.0335\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 924.5362 - val_loss: 27.7848\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1084.4602 - val_loss: 240.7663\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 20565.4215 - val_loss: 5335.3662\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 8381949.1581 - val_loss: 66836.1250\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 9477490.7974 - val_loss: 835076.3125\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1004376518.4533 - val_loss: 199303072.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 198123929.1029 - val_loss: 638495360.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 472849415945.8765 - val_loss: 19942825984.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 189912859584.7901 - val_loss: 71595925504.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 162017525760.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.2665 - val_loss: 1.2054\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0693 - val_loss: 0.8711\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8121 - val_loss: 0.7938\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7536 - val_loss: 0.7526\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6885 - val_loss: 0.7214\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6472 - val_loss: 0.6964\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6427 - val_loss: 0.6753\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6323 - val_loss: 0.6549\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6059 - val_loss: 0.6383\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5870 - val_loss: 0.6232\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5994 - val_loss: 0.6097\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5812 - val_loss: 0.5981\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5687 - val_loss: 0.5876\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5522 - val_loss: 0.5788\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5218 - val_loss: 0.5701\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5317 - val_loss: 0.5622\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5067 - val_loss: 0.5545\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5179 - val_loss: 0.5491\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4975 - val_loss: 0.5477\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5006 - val_loss: 0.5403\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4924 - val_loss: 0.5377\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4979 - val_loss: 0.5364\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5143 - val_loss: 0.5318\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4686 - val_loss: 0.5267\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5128 - val_loss: 0.5295\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5021 - val_loss: 0.5220\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5078 - val_loss: 0.5220\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4905 - val_loss: 0.5162\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4840 - val_loss: 0.5158\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5003 - val_loss: 0.5208\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4938 - val_loss: 0.5146\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4818 - val_loss: 0.5110\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4949 - val_loss: 0.5070\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4717 - val_loss: 0.5071\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4855 - val_loss: 0.5097\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4852 - val_loss: 0.5047\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4751 - val_loss: 0.5001\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 0.5018\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4832 - val_loss: 0.4975\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.4961\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.4951\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4753 - val_loss: 0.4933\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4769 - val_loss: 0.4978\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4718 - val_loss: 0.4911\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4639 - val_loss: 0.4896\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4724 - val_loss: 0.4894\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4642 - val_loss: 0.4911\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4753 - val_loss: 0.4918\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4789 - val_loss: 0.4860\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4573 - val_loss: 0.4852\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4627 - val_loss: 0.4878\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 0.4834\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4551 - val_loss: 0.4828\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4635 - val_loss: 0.4845\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4531 - val_loss: 0.4850\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4689 - val_loss: 0.4870\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.4840\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4498 - val_loss: 0.4793\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.4820\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4512 - val_loss: 0.4778\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.4824\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4531 - val_loss: 0.4757\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.4772\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4392 - val_loss: 0.4765\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4641 - val_loss: 0.4740\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.4745\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4420 - val_loss: 0.4792\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4427 - val_loss: 0.4755\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4630 - val_loss: 0.4721\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4542 - val_loss: 0.4705\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 0.4722\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4618 - val_loss: 0.4690\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 0.4686\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4517 - val_loss: 0.4729\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4402 - val_loss: 0.4680\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4305 - val_loss: 0.4676\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4352 - val_loss: 0.4670\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.4657\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4551 - val_loss: 0.4672\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4477 - val_loss: 0.4653\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4138 - val_loss: 0.4651\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4197 - val_loss: 0.4653\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.4635\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4383 - val_loss: 0.4615\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4558 - val_loss: 0.4621\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4421 - val_loss: 0.4608\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 0.4608\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4369 - val_loss: 0.4597\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4334 - val_loss: 0.4606\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4468 - val_loss: 0.4606\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.4410 - val_loss: 0.4581\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4493 - val_loss: 0.4580\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4291 - val_loss: 0.4577\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4564\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4539 - val_loss: 0.4562\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 0.4569\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 0.4557\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4300 - val_loss: 0.4556\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4501 - val_loss: 0.4546\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4175 - val_loss: 0.4544\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4208\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.1785 - val_loss: 0.8967\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8013 - val_loss: 0.7142\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6410 - val_loss: 0.6629\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6077 - val_loss: 0.6277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5761 - val_loss: 0.6010\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5409 - val_loss: 0.5807\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5187 - val_loss: 0.5646\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5152 - val_loss: 0.5516\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5447 - val_loss: 0.5409\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4756 - val_loss: 0.5311\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4709 - val_loss: 0.5240\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.5185\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4907 - val_loss: 0.5121\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4846 - val_loss: 0.5079\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4877 - val_loss: 0.5027\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.4989\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4777 - val_loss: 0.4962\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.4929\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4642 - val_loss: 0.4902\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4673 - val_loss: 0.4867\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4634 - val_loss: 0.4848\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 0.4829\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4390 - val_loss: 0.4807\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4457 - val_loss: 0.4791\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4542 - val_loss: 0.4774\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4497 - val_loss: 0.4762\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4525 - val_loss: 0.4749\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4405 - val_loss: 0.4728\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4439 - val_loss: 0.4723\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4437 - val_loss: 0.4706\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4467 - val_loss: 0.4698\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4317 - val_loss: 0.4680\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4346 - val_loss: 0.4671\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4290 - val_loss: 0.4656\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4446 - val_loss: 0.4646\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4391 - val_loss: 0.4645\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4628\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4262 - val_loss: 0.4621\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4337 - val_loss: 0.4611\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4243 - val_loss: 0.4600\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4216 - val_loss: 0.4591\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4438 - val_loss: 0.4585\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4401 - val_loss: 0.4579\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4381 - val_loss: 0.4572\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.4557\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4227 - val_loss: 0.4550\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4279 - val_loss: 0.4545\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4263 - val_loss: 0.4543\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4180 - val_loss: 0.4531\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4293 - val_loss: 0.4523\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.4516\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4193 - val_loss: 0.4507\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4113 - val_loss: 0.4503\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4251 - val_loss: 0.4501\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4140 - val_loss: 0.4494\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4279 - val_loss: 0.4482\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4169 - val_loss: 0.4480\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4211 - val_loss: 0.4470\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4252 - val_loss: 0.4465\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4279 - val_loss: 0.4457\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4204 - val_loss: 0.4452\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4092 - val_loss: 0.4444\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4363 - val_loss: 0.4440\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4087 - val_loss: 0.4436\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4261 - val_loss: 0.4433\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4155 - val_loss: 0.4425\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4017 - val_loss: 0.4416\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4202 - val_loss: 0.4414\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4212 - val_loss: 0.4410\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4044 - val_loss: 0.4410\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4142 - val_loss: 0.4397\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4306 - val_loss: 0.4395\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4172 - val_loss: 0.4389\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 0.4382\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3890 - val_loss: 0.4370\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4085 - val_loss: 0.4371\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4188 - val_loss: 0.4366\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4166 - val_loss: 0.4358\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 0.4363\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.4348\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4093 - val_loss: 0.4344\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.4340\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4056 - val_loss: 0.4334\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4083 - val_loss: 0.4334\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4129 - val_loss: 0.4325\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.4322\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3874 - val_loss: 0.4313\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3920 - val_loss: 0.4314\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4050 - val_loss: 0.4310\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4013 - val_loss: 0.4302\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3984 - val_loss: 0.4299\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 0.4293\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4044 - val_loss: 0.4287\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4098 - val_loss: 0.4285\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3999 - val_loss: 0.4279\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3781 - val_loss: 0.4273\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3987 - val_loss: 0.4269\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.4264\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.4261\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3921 - val_loss: 0.4259\n",
      "121/121 [==============================] - 0s 863us/step - loss: 0.4092\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.5597 - val_loss: 1.0566\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9374 - val_loss: 0.8593\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8146 - val_loss: 0.8026\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7310 - val_loss: 0.7645\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6943 - val_loss: 0.7328\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6592 - val_loss: 0.7055\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6361 - val_loss: 0.6831\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6207 - val_loss: 0.6628\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5959 - val_loss: 0.6448\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5990 - val_loss: 0.6284\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5558 - val_loss: 0.6138\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.5997\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5419 - val_loss: 0.5878\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5435 - val_loss: 0.5766\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5152 - val_loss: 0.5658\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4908 - val_loss: 0.5566\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5080 - val_loss: 0.5491\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4955 - val_loss: 0.5408\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 0.5345\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4931 - val_loss: 0.5294\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4790 - val_loss: 0.5245\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4711 - val_loss: 0.5195\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5009 - val_loss: 0.5161\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4697 - val_loss: 0.5124\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4799 - val_loss: 0.5087\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4852 - val_loss: 0.5062\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5036\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4582 - val_loss: 0.5011\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.4990\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4701 - val_loss: 0.4962\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4461 - val_loss: 0.4946\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4712 - val_loss: 0.4928\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4509 - val_loss: 0.4911\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.4895\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 0.4877\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4860\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.4844\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4609 - val_loss: 0.4832\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4818\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4425 - val_loss: 0.4811\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.4799\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4344 - val_loss: 0.4782\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4428 - val_loss: 0.4773\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4321 - val_loss: 0.4758\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4384 - val_loss: 0.4755\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4232 - val_loss: 0.4741\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4477 - val_loss: 0.4735\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4392 - val_loss: 0.4724\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4326 - val_loss: 0.4715\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4273 - val_loss: 0.4698\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4687\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.4674\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.4672\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.4663\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4383 - val_loss: 0.4658\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4259 - val_loss: 0.4645\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.4641\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4364 - val_loss: 0.4628\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4339 - val_loss: 0.4622\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4108 - val_loss: 0.4613\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4258 - val_loss: 0.4603\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.4603\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4332 - val_loss: 0.4594\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4212 - val_loss: 0.4595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4117 - val_loss: 0.4580\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.4573\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4159 - val_loss: 0.4567\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4190 - val_loss: 0.4561\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4185 - val_loss: 0.4556\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4119 - val_loss: 0.4552\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4309 - val_loss: 0.4541\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4022 - val_loss: 0.4541\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 0.4535\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 0.4108 - val_loss: 0.4529\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4133 - val_loss: 0.4520\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4089 - val_loss: 0.4518\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4113 - val_loss: 0.4519\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4270 - val_loss: 0.4507\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 0.4506\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4094 - val_loss: 0.4491\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 0.4492\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4128 - val_loss: 0.4485\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4214 - val_loss: 0.4481\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4014 - val_loss: 0.4478\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3815 - val_loss: 0.4472\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4131 - val_loss: 0.4463\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4123 - val_loss: 0.4457\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4002 - val_loss: 0.4452\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4149 - val_loss: 0.4451\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.4450\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4119 - val_loss: 0.4443\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4048 - val_loss: 0.4442\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3933 - val_loss: 0.4433\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.4424\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4016 - val_loss: 0.4432\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.4425\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4012 - val_loss: 0.4409\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.4412\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4189 - val_loss: 0.4418\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4061 - val_loss: 0.4406\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4368\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9055 - val_loss: 0.5579\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5640 - val_loss: 0.5995\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5587 - val_loss: 0.5443\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5254 - val_loss: 0.5543\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5617 - val_loss: 0.5385\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5223 - val_loss: 0.7497\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6238 - val_loss: 0.5424\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5281 - val_loss: 1.2122\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6513 - val_loss: 0.5423\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6041 - val_loss: 0.5484\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6197 - val_loss: 0.5428\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5507 - val_loss: 0.5445\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5746 - val_loss: 0.5391\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5716 - val_loss: 0.5446\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5715 - val_loss: 0.5372\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 0.5495\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6191 - val_loss: 0.5406\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5620 - val_loss: 0.5480\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5618 - val_loss: 0.5468\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 0.5593\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5889 - val_loss: 0.5480\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5344 - val_loss: 0.5879\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5370 - val_loss: 0.5605\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5495 - val_loss: 0.5503\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5374 - val_loss: 0.5449\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.5053\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9699 - val_loss: 0.6570\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0133 - val_loss: 1.1171\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 57.0654 - val_loss: 62.2173\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5560.7977 - val_loss: 3323.3696\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 124721.2736 - val_loss: 221164.5781\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 17285848.5453 - val_loss: 11784797.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 627171703.5926 - val_loss: 719539264.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 22752540971.1934 - val_loss: 43671076864.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2390113733492.9385 - val_loss: 2510340751360.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 512092482446829.0625 - val_loss: 141542106857472.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 34397295876549832.0000 - val_loss: 8267216118087680.0000\n",
      "121/121 [==============================] - 0s 968us/step - loss: 1420003461793054720.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1199 - val_loss: 0.6269\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7182 - val_loss: 0.5757\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 445.9381 - val_loss: 2.6280\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 175.6201 - val_loss: 21.8097\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2073.5274 - val_loss: 446.2317\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2176602.8059 - val_loss: 26422.6934\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5115111.8099 - val_loss: 1984247.5000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 39917232.9712 - val_loss: 3111546.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 208177444.0808 - val_loss: 78099824.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 13709417825.6461 - val_loss: 2763023872.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 884051100349.6296 - val_loss: 41698594816.0000\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2915055613564.3130 - val_loss: 420523540480.0000\n",
      "121/121 [==============================] - 0s 931us/step - loss: 848704962560.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5165 - val_loss: 1.3641\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2342 - val_loss: 0.8990\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8927 - val_loss: 0.8217\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7791 - val_loss: 0.7898\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7736 - val_loss: 0.7694\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7085 - val_loss: 0.7517\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6825 - val_loss: 0.7355\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6953 - val_loss: 0.7203\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6792 - val_loss: 0.7065\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6363 - val_loss: 0.6931\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6351 - val_loss: 0.6808\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6296 - val_loss: 0.6692\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6399 - val_loss: 0.6582\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6406 - val_loss: 0.6480\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6383\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.6293\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6081 - val_loss: 0.6206\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5847 - val_loss: 0.6125\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5682 - val_loss: 0.6048\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5480 - val_loss: 0.5975\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5686 - val_loss: 0.5905\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5681 - val_loss: 0.5841\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5512 - val_loss: 0.5780\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5476 - val_loss: 0.5723\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5393 - val_loss: 0.5672\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5313 - val_loss: 0.5619\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5414 - val_loss: 0.5573\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5436 - val_loss: 0.5531\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5094 - val_loss: 0.5488\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5077 - val_loss: 0.5451\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5178 - val_loss: 0.5413\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5379\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5014 - val_loss: 0.5343\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4989 - val_loss: 0.5315\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5107 - val_loss: 0.5289\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5095 - val_loss: 0.5259\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5174 - val_loss: 0.5233\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5118 - val_loss: 0.5211\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.5187\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5111 - val_loss: 0.5159\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.5136\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4730 - val_loss: 0.5117\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5159 - val_loss: 0.5099\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4888 - val_loss: 0.5081\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 0.5066\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4780 - val_loss: 0.5046\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4806 - val_loss: 0.5033\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4751 - val_loss: 0.5013\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4918 - val_loss: 0.5000\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4705 - val_loss: 0.4989\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4919 - val_loss: 0.4973\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4833 - val_loss: 0.4960\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4464 - val_loss: 0.4948\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4910 - val_loss: 0.4936\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4523 - val_loss: 0.4924\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.4913\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4767 - val_loss: 0.4904\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.4893\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4567 - val_loss: 0.4884\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.4874\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4702 - val_loss: 0.4864\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4715 - val_loss: 0.4854\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.4845\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 0.4836\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.4829\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4465 - val_loss: 0.4820\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4470 - val_loss: 0.4814\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4667 - val_loss: 0.4808\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.4798\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4570 - val_loss: 0.4789\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 0.4780\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4491 - val_loss: 0.4774\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4474 - val_loss: 0.4767\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4683 - val_loss: 0.4761\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4220 - val_loss: 0.4753\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.4746\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4706 - val_loss: 0.4743\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4450 - val_loss: 0.4733\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.4727\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4488 - val_loss: 0.4719\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4344 - val_loss: 0.4713\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4679 - val_loss: 0.4708\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4520 - val_loss: 0.4702\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4472 - val_loss: 0.4698\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4684 - val_loss: 0.4692\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4413 - val_loss: 0.4684\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4330 - val_loss: 0.4680\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4276 - val_loss: 0.4674\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.4669\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4285 - val_loss: 0.4664\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4392 - val_loss: 0.4659\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.4654\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4649\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 0.4641\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 0.4637\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4393 - val_loss: 0.4630\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4329 - val_loss: 0.4625\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 0.4622\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.4617\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.4613\n",
      "121/121 [==============================] - 0s 975us/step - loss: 0.4267\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.4492 - val_loss: 1.3648\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2043 - val_loss: 0.8530\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.7735 - val_loss: 0.7448\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7022 - val_loss: 0.7125\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6603 - val_loss: 0.6951\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6586 - val_loss: 0.6808\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6236 - val_loss: 0.6677\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6334 - val_loss: 0.6552\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6236 - val_loss: 0.6438\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5821 - val_loss: 0.6334\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5888 - val_loss: 0.6234\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5938 - val_loss: 0.6137\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5770 - val_loss: 0.6054\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5525 - val_loss: 0.5971\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5480 - val_loss: 0.5897\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5493 - val_loss: 0.5829\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5157 - val_loss: 0.5769\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5464 - val_loss: 0.5707\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5096 - val_loss: 0.5652\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5219 - val_loss: 0.5601\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4988 - val_loss: 0.5556\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4881 - val_loss: 0.5520\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5134 - val_loss: 0.5485\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5259 - val_loss: 0.5444\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5146 - val_loss: 0.5406\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5256 - val_loss: 0.5381\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5142 - val_loss: 0.5348\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4960 - val_loss: 0.5320\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4901 - val_loss: 0.5290\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4961 - val_loss: 0.5264\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4944 - val_loss: 0.5237\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5136 - val_loss: 0.5218\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4976 - val_loss: 0.5199\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4870 - val_loss: 0.5175\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4849 - val_loss: 0.5155\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4965 - val_loss: 0.5137\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4828 - val_loss: 0.5124\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4627 - val_loss: 0.5102\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4712 - val_loss: 0.5089\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5070\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4667 - val_loss: 0.5054\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4716 - val_loss: 0.5040\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4739 - val_loss: 0.5026\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4458 - val_loss: 0.5011\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4535 - val_loss: 0.5000\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.4987\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4714 - val_loss: 0.4974\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4665 - val_loss: 0.4961\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4508 - val_loss: 0.4951\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4670 - val_loss: 0.4940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4704 - val_loss: 0.4929\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4662 - val_loss: 0.4918\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4529 - val_loss: 0.4909\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.4901\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4468 - val_loss: 0.4887\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.4876\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4468 - val_loss: 0.4869\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.4862\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4604 - val_loss: 0.4855\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4531 - val_loss: 0.4844\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4498 - val_loss: 0.4836\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 0.4828\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4636 - val_loss: 0.4819\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4602 - val_loss: 0.4812\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 0.4806\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 0.4798\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4398 - val_loss: 0.4787\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4585 - val_loss: 0.4780\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4610 - val_loss: 0.4774\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4550 - val_loss: 0.4769\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4466 - val_loss: 0.4763\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4621 - val_loss: 0.4753\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.4747\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4434 - val_loss: 0.4740\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4428 - val_loss: 0.4736\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4726\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4343 - val_loss: 0.4721\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4402 - val_loss: 0.4718\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4263 - val_loss: 0.4708\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4624 - val_loss: 0.4704\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4204 - val_loss: 0.4699\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4344 - val_loss: 0.4693\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4250 - val_loss: 0.4688\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4683\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4500 - val_loss: 0.4676\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 0.4672\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4560 - val_loss: 0.4665\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4110 - val_loss: 0.4661\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4282 - val_loss: 0.4657\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4204 - val_loss: 0.4652\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4341 - val_loss: 0.4646\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4372 - val_loss: 0.4641\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4131 - val_loss: 0.4634\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4191 - val_loss: 0.4631\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4275 - val_loss: 0.4625\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4315 - val_loss: 0.4619\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4218 - val_loss: 0.4617\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4140 - val_loss: 0.4611\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4454 - val_loss: 0.4605\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4397 - val_loss: 0.4603\n",
      "121/121 [==============================] - 0s 899us/step - loss: 0.4463\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.5619 - val_loss: 1.5355\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2488 - val_loss: 0.9503\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8776 - val_loss: 0.8344\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7518 - val_loss: 0.7917\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7356 - val_loss: 0.7693\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7088 - val_loss: 0.7528\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7019 - val_loss: 0.7380\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6903 - val_loss: 0.7249\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6544 - val_loss: 0.7113\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6659 - val_loss: 0.6989\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6140 - val_loss: 0.6869\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6261 - val_loss: 0.6756\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6007 - val_loss: 0.6649\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6106 - val_loss: 0.6548\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5818 - val_loss: 0.6446\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6154 - val_loss: 0.6359\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6087 - val_loss: 0.6267\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5525 - val_loss: 0.6185\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5705 - val_loss: 0.6109\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5795 - val_loss: 0.6044\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5622 - val_loss: 0.5975\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5384 - val_loss: 0.5911\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5616 - val_loss: 0.5851\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5199 - val_loss: 0.5795\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5484 - val_loss: 0.5745\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5406 - val_loss: 0.5697\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5193 - val_loss: 0.5652\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5007 - val_loss: 0.5610\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4924 - val_loss: 0.5572\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5050 - val_loss: 0.5534\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5243 - val_loss: 0.5496\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4912 - val_loss: 0.5463\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4959 - val_loss: 0.5434\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4933 - val_loss: 0.5401\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4913 - val_loss: 0.5370\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4828 - val_loss: 0.5341\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4996 - val_loss: 0.5314\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 0.5293\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 0.5269\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.5245\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4857 - val_loss: 0.5222\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4528 - val_loss: 0.5202\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4740 - val_loss: 0.5183\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4981 - val_loss: 0.5168\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4722 - val_loss: 0.5151\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4675 - val_loss: 0.5135\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4721 - val_loss: 0.5115\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4702 - val_loss: 0.5100\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4590 - val_loss: 0.5086\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4837 - val_loss: 0.5073\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.5056\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4787 - val_loss: 0.5045\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4748 - val_loss: 0.5030\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.5018\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 0.5011\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4738 - val_loss: 0.4997\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4720 - val_loss: 0.4985\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.4976\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4578 - val_loss: 0.4965\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.4959\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4676 - val_loss: 0.4949\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4594 - val_loss: 0.4938\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4727 - val_loss: 0.4933\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4442 - val_loss: 0.4923\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4406 - val_loss: 0.4913\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4718 - val_loss: 0.4903\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4548 - val_loss: 0.4897\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.4890\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4771 - val_loss: 0.4883\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4624 - val_loss: 0.4873\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4571 - val_loss: 0.4868\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4435 - val_loss: 0.4860\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 0.4855\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4531 - val_loss: 0.4845\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 0.4839\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4529 - val_loss: 0.4834\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4412 - val_loss: 0.4828\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4251 - val_loss: 0.4821\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.4813\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4461 - val_loss: 0.4808\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.4804\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4482 - val_loss: 0.4799\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4439 - val_loss: 0.4792\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4491 - val_loss: 0.4788\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.4780\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4374 - val_loss: 0.4774\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.4768\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4575 - val_loss: 0.4763\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4184 - val_loss: 0.4760\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4455 - val_loss: 0.4752\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4278 - val_loss: 0.4747\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4335 - val_loss: 0.4743\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4401 - val_loss: 0.4738\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4316 - val_loss: 0.4735\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4415 - val_loss: 0.4728\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.4723\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4375 - val_loss: 0.4717\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4456 - val_loss: 0.4715\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4525 - val_loss: 0.4709\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4307 - val_loss: 0.4702\n",
      "121/121 [==============================] - 0s 891us/step - loss: 0.4529\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.6667 - val_loss: 1.0390\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9362 - val_loss: 0.7887\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7617 - val_loss: 0.7385\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7042 - val_loss: 0.7038\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6472 - val_loss: 0.6753\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6359 - val_loss: 0.6524\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5901 - val_loss: 0.6337\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5773 - val_loss: 0.6167\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5829 - val_loss: 0.6013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5645 - val_loss: 0.5877\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5738 - val_loss: 0.5776\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5587 - val_loss: 0.5688\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5477 - val_loss: 0.5604\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5078 - val_loss: 0.5533\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5101 - val_loss: 0.5479\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 0.5432\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5205 - val_loss: 0.5383\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5068 - val_loss: 0.5338\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5034 - val_loss: 0.5296\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5144 - val_loss: 0.5261\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5116 - val_loss: 0.5230\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5118 - val_loss: 0.5202\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4897 - val_loss: 0.5174\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5040 - val_loss: 0.5149\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.5114\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4883 - val_loss: 0.5092\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4802 - val_loss: 0.5060\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4668 - val_loss: 0.5041\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4841 - val_loss: 0.5017\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4779 - val_loss: 0.5007\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4802 - val_loss: 0.4982\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.4969\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.4943\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.4927\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.4914\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4783 - val_loss: 0.4890\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4637 - val_loss: 0.4875\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4572 - val_loss: 0.4867\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4571 - val_loss: 0.4848\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4475 - val_loss: 0.4834\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4518 - val_loss: 0.4825\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4799 - val_loss: 0.4809\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.4785\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.4786\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4499 - val_loss: 0.4765\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4450 - val_loss: 0.4764\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4268 - val_loss: 0.4750\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4592 - val_loss: 0.4738\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4388 - val_loss: 0.4723\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4343 - val_loss: 0.4715\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.4702\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4605 - val_loss: 0.4694\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4342 - val_loss: 0.4678\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4733 - val_loss: 0.4678\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4460 - val_loss: 0.4660\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4445 - val_loss: 0.4650\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4554 - val_loss: 0.4645\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.4636\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4500 - val_loss: 0.4629\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4113 - val_loss: 0.4620\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.4609\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4361 - val_loss: 0.4606\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4512 - val_loss: 0.4594\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4372 - val_loss: 0.4588\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4206 - val_loss: 0.4583\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4468 - val_loss: 0.4573\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 0.4574\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4481 - val_loss: 0.4560\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 0.4556\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4318 - val_loss: 0.4546\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4417 - val_loss: 0.4548\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.4535\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4528\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4392 - val_loss: 0.4525\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4333 - val_loss: 0.4516\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.4514\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4362 - val_loss: 0.4510\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 0.4503\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4431 - val_loss: 0.4494\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4350 - val_loss: 0.4491\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4244 - val_loss: 0.4489\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4208 - val_loss: 0.4478\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4479 - val_loss: 0.4472\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4195 - val_loss: 0.4468\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4256 - val_loss: 0.4465\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4302 - val_loss: 0.4464\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4148 - val_loss: 0.4454\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4140 - val_loss: 0.4445\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4070 - val_loss: 0.4442\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 0.4437\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4150 - val_loss: 0.4432\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4149 - val_loss: 0.4428\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4313 - val_loss: 0.4427\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.4418\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4184 - val_loss: 0.4415\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4131 - val_loss: 0.4409\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4288 - val_loss: 0.4408\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.4400\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4397\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4173 - val_loss: 0.4397\n",
      "121/121 [==============================] - 0s 864us/step - loss: 0.4006\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.4717 - val_loss: 1.9228\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4627 - val_loss: 0.9745\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.8925 - val_loss: 0.8258\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7539 - val_loss: 0.7624\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7087 - val_loss: 0.7238\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6820 - val_loss: 0.6974\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6379 - val_loss: 0.6756\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6024 - val_loss: 0.6578\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6132 - val_loss: 0.6431\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5897 - val_loss: 0.6292\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5831 - val_loss: 0.6188\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5513 - val_loss: 0.6065\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5483 - val_loss: 0.5978\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5855 - val_loss: 0.5887\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5372 - val_loss: 0.5809\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5182 - val_loss: 0.5714\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5278 - val_loss: 0.5660\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5345 - val_loss: 0.5614\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5298 - val_loss: 0.5529\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5045 - val_loss: 0.5480\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 0.5416\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5040 - val_loss: 0.5371\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5023 - val_loss: 0.5342\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5163 - val_loss: 0.5287\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4865 - val_loss: 0.5249\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4610 - val_loss: 0.5218\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.5200\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4887 - val_loss: 0.5152\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.5122\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4999 - val_loss: 0.5106\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4774 - val_loss: 0.5077\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4745 - val_loss: 0.5052\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4749 - val_loss: 0.5042\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 0.5019\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.5014\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.4993\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4780 - val_loss: 0.4960\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.4970\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4595 - val_loss: 0.4952\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.4938\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4696 - val_loss: 0.4907\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4638 - val_loss: 0.4900\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4631 - val_loss: 0.4886\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4362 - val_loss: 0.4878\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4491 - val_loss: 0.4866\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4603 - val_loss: 0.4866\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4500 - val_loss: 0.4844\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4634 - val_loss: 0.4840\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4628 - val_loss: 0.4834\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4626 - val_loss: 0.4814\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4648 - val_loss: 0.4805\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4649 - val_loss: 0.4809\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4593 - val_loss: 0.4793\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4381 - val_loss: 0.4788\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4471 - val_loss: 0.4773\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 0.4761\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4680 - val_loss: 0.4764\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4587 - val_loss: 0.4751\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4329 - val_loss: 0.4741\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4418 - val_loss: 0.4739\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4341 - val_loss: 0.4730\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.4723\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4217 - val_loss: 0.4718\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4400 - val_loss: 0.4709\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 0.4701\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4391 - val_loss: 0.4697\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4300 - val_loss: 0.4689\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.4689\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4174 - val_loss: 0.4675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4341 - val_loss: 0.4668\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4358 - val_loss: 0.4669\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4195 - val_loss: 0.4658\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4653\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4647\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4449 - val_loss: 0.4649\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4384 - val_loss: 0.4639\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4271 - val_loss: 0.4635\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4181 - val_loss: 0.4622\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.4616\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4311 - val_loss: 0.4609\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4441 - val_loss: 0.4605\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4346 - val_loss: 0.4602\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4371 - val_loss: 0.4600\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4574 - val_loss: 0.4592\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4162 - val_loss: 0.4586\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4001 - val_loss: 0.4578\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4190 - val_loss: 0.4571\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4166 - val_loss: 0.4566\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4280 - val_loss: 0.4561\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4557\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4310 - val_loss: 0.4549\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4230 - val_loss: 0.4545\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4264 - val_loss: 0.4538\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4022 - val_loss: 0.4532\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4130 - val_loss: 0.4527\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4252 - val_loss: 0.4522\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4231 - val_loss: 0.4513\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4312 - val_loss: 0.4509\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4113 - val_loss: 0.4505\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4044 - val_loss: 0.4499\n",
      "121/121 [==============================] - 0s 861us/step - loss: 0.4389\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.8843 - val_loss: 0.9785\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8447 - val_loss: 0.7657\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7043 - val_loss: 0.7311\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6696 - val_loss: 0.7078\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6464 - val_loss: 0.6872\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6134 - val_loss: 0.6671\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6041 - val_loss: 0.6503\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5874 - val_loss: 0.6335\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5776 - val_loss: 0.6188\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5491 - val_loss: 0.6062\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5542 - val_loss: 0.5945\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5384 - val_loss: 0.5839\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5389 - val_loss: 0.5749\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5040 - val_loss: 0.5668\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 0.5590\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5201 - val_loss: 0.5523\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4803 - val_loss: 0.5458\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4902 - val_loss: 0.5404\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5047 - val_loss: 0.5361\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4925 - val_loss: 0.5314\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5007 - val_loss: 0.5274\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4907 - val_loss: 0.5240\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4615 - val_loss: 0.5208\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5066 - val_loss: 0.5179\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4917 - val_loss: 0.5154\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4546 - val_loss: 0.5127\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.5105\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4740 - val_loss: 0.5081\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4507 - val_loss: 0.5061\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4836 - val_loss: 0.5039\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4834 - val_loss: 0.5021\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4556 - val_loss: 0.5013\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4472 - val_loss: 0.4993\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 0.4982\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4657 - val_loss: 0.4966\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4703 - val_loss: 0.4951\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4608 - val_loss: 0.4937\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4520 - val_loss: 0.4926\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4492 - val_loss: 0.4914\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4670 - val_loss: 0.4902\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4589 - val_loss: 0.4893\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4525 - val_loss: 0.4880\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4715 - val_loss: 0.4869\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4776 - val_loss: 0.4854\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.4847\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4342 - val_loss: 0.4837\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.4823\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4340 - val_loss: 0.4814\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.4807\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4413 - val_loss: 0.4798\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4406 - val_loss: 0.4789\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4505 - val_loss: 0.4782\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4382 - val_loss: 0.4772\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.4763\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 0.4758\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4424 - val_loss: 0.4744\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.4739\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4388 - val_loss: 0.4732\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4388 - val_loss: 0.4721\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4269 - val_loss: 0.4717\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4369 - val_loss: 0.4704\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4509 - val_loss: 0.4702\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4695\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4417 - val_loss: 0.4686\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.4675\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4312 - val_loss: 0.4672\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4429 - val_loss: 0.4662\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.4652\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4484 - val_loss: 0.4651\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4321 - val_loss: 0.4641\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.4637\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4232 - val_loss: 0.4626\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4287 - val_loss: 0.4625\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4432 - val_loss: 0.4615\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.4612\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.4603\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 0.4594\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4342 - val_loss: 0.4584\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.4578\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4235 - val_loss: 0.4574\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4236 - val_loss: 0.4570\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4168 - val_loss: 0.4560\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4283 - val_loss: 0.4553\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4426 - val_loss: 0.4548\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4195 - val_loss: 0.4539\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4218 - val_loss: 0.4532\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.4528\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4272 - val_loss: 0.4519\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.4512\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4031 - val_loss: 0.4508\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4110 - val_loss: 0.4506\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4340 - val_loss: 0.4497\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4308 - val_loss: 0.4491\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4059 - val_loss: 0.4486\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4138 - val_loss: 0.4481\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4228 - val_loss: 0.4473\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.4469\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4291 - val_loss: 0.4460\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4231 - val_loss: 0.4451\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4193 - val_loss: 0.4442\n",
      "121/121 [==============================] - 0s 956us/step - loss: 0.4345\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3681 - val_loss: 0.7458\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6681 - val_loss: 0.6331\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5786 - val_loss: 0.5819\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5531 - val_loss: 0.5530\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5358 - val_loss: 0.5296\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5193 - val_loss: 0.5188\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4735 - val_loss: 0.5033\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4462 - val_loss: 0.4934\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4559 - val_loss: 0.4792\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4621 - val_loss: 0.4742\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4506 - val_loss: 0.4778\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4726 - val_loss: 0.4607\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4451 - val_loss: 0.4556\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4452 - val_loss: 0.4586\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4252 - val_loss: 0.4464\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4005 - val_loss: 0.4439\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4520 - val_loss: 0.4419\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4225 - val_loss: 0.4455\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.4319\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4177 - val_loss: 0.4315\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4233 - val_loss: 0.4298\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3948 - val_loss: 0.4282\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4065 - val_loss: 0.4344\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4109 - val_loss: 0.4172\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4309 - val_loss: 0.4174\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4015 - val_loss: 0.4126\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4098 - val_loss: 0.4124\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3959 - val_loss: 0.4112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4026 - val_loss: 0.4165\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3967 - val_loss: 0.4048\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3947 - val_loss: 0.4040\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3816 - val_loss: 0.4030\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3825 - val_loss: 0.3968\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3934 - val_loss: 0.3956\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3751 - val_loss: 0.4048\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.3911\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3664 - val_loss: 0.3962\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.3860\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.3886\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3678 - val_loss: 0.3882\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3647 - val_loss: 0.3815\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3520 - val_loss: 0.3808\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3585 - val_loss: 0.3797\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3484 - val_loss: 0.3790\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3589 - val_loss: 0.3879\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3466 - val_loss: 0.3792\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.3740\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3583 - val_loss: 0.3752\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3505 - val_loss: 0.3701\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3532 - val_loss: 0.3701\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3471 - val_loss: 0.3697\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3468 - val_loss: 0.3662\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3435 - val_loss: 0.3681\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3342 - val_loss: 0.3662\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3379 - val_loss: 0.3637\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3315 - val_loss: 0.3663\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3310 - val_loss: 0.3618\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3393 - val_loss: 0.3681\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3410 - val_loss: 0.3679\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3280 - val_loss: 0.3643\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3374 - val_loss: 0.3576\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3217 - val_loss: 0.3596\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3302 - val_loss: 0.3518\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.3549\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3360 - val_loss: 0.3521\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3375 - val_loss: 0.3572\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3332 - val_loss: 0.3542\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3145 - val_loss: 0.3511\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3202 - val_loss: 0.3469\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3215 - val_loss: 0.3481\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3221 - val_loss: 0.3465\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3176 - val_loss: 0.3560\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3222 - val_loss: 0.3601\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3162 - val_loss: 0.3429\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3203 - val_loss: 0.3760\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3207 - val_loss: 0.3414\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3082 - val_loss: 0.3505\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3106 - val_loss: 0.3403\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3072 - val_loss: 0.3413\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3229 - val_loss: 0.3414\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3002 - val_loss: 0.3426\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2914 - val_loss: 0.3396\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2997 - val_loss: 0.3380\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2951 - val_loss: 0.3403\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2891 - val_loss: 0.3536\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3017 - val_loss: 0.3357\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2954 - val_loss: 0.3333\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2958 - val_loss: 0.3363\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2993 - val_loss: 0.3368\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3020 - val_loss: 0.3325\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3086 - val_loss: 0.3433\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3097 - val_loss: 0.3524\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2950 - val_loss: 0.3492\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3014 - val_loss: 0.3483\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3024 - val_loss: 0.3541\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3287 - val_loss: 0.3461\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2973 - val_loss: 0.3365\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3057 - val_loss: 0.3386\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2911 - val_loss: 0.3271\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2733 - val_loss: 0.3289\n",
      "121/121 [==============================] - 0s 939us/step - loss: 0.3021\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4151 - val_loss: 2.6666\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.2564 - val_loss: 0.6550\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5888 - val_loss: 0.5913\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5443 - val_loss: 0.5479\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5143 - val_loss: 0.5130\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 0.4945\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4509 - val_loss: 0.4815\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4600 - val_loss: 0.4687\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4387 - val_loss: 0.4569\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4409 - val_loss: 0.4484\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4253 - val_loss: 0.4446\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4249 - val_loss: 0.4369\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4024 - val_loss: 0.4327\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4003 - val_loss: 0.4251\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3964 - val_loss: 0.4220\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4106 - val_loss: 0.4159\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.4158\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3938 - val_loss: 0.4108\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3974 - val_loss: 0.4116\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 0.4029\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3600 - val_loss: 0.4028\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.3987\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3815 - val_loss: 0.4025\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3623 - val_loss: 0.3917\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3510 - val_loss: 0.3901\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3643 - val_loss: 0.3928\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3620 - val_loss: 0.3884\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3659 - val_loss: 0.3902\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 0.3840\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3559 - val_loss: 0.3804\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3537 - val_loss: 0.3850\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3357 - val_loss: 0.3752\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3403 - val_loss: 0.3746\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3388 - val_loss: 0.3740\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3333 - val_loss: 0.3701\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3508 - val_loss: 0.3715\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3289 - val_loss: 0.3708\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3316 - val_loss: 0.3686\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3326 - val_loss: 0.3645\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3381 - val_loss: 0.3618\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3220 - val_loss: 0.3610\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3253 - val_loss: 0.3647\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3396 - val_loss: 0.3588\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3121 - val_loss: 0.3572\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3201 - val_loss: 0.3532\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3194 - val_loss: 0.3567\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3045 - val_loss: 0.3517\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3129 - val_loss: 0.3586\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3013 - val_loss: 0.3503\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3076 - val_loss: 0.3487\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2989 - val_loss: 0.3537\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 0.3154 - val_loss: 0.3494\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3220 - val_loss: 0.3471\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3168 - val_loss: 0.3474\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2908 - val_loss: 0.3481\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3104 - val_loss: 0.3433\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2947 - val_loss: 0.3617\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3168 - val_loss: 0.3433\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3009 - val_loss: 0.3415\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3156 - val_loss: 0.3472\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2806 - val_loss: 0.3382\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2849 - val_loss: 0.3397\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3015 - val_loss: 0.3395\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2856 - val_loss: 0.3380\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2955 - val_loss: 0.3400\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2953 - val_loss: 0.3348\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2826 - val_loss: 0.3495\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2956 - val_loss: 0.3354\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2936 - val_loss: 0.3368\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3051 - val_loss: 0.3374\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2866 - val_loss: 0.3325\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2968 - val_loss: 0.3358\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2768 - val_loss: 0.3337\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2960 - val_loss: 0.3335\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2839 - val_loss: 0.3345\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2895 - val_loss: 0.3304\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2846 - val_loss: 0.3403\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2934 - val_loss: 0.3308\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2880 - val_loss: 0.3333\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2762 - val_loss: 0.3328\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2767 - val_loss: 0.3324\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2908 - val_loss: 0.3284\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2841 - val_loss: 0.3267\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2691 - val_loss: 0.3295\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2772 - val_loss: 0.3464\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2903 - val_loss: 0.3281\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2744 - val_loss: 0.3377\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2948 - val_loss: 0.3344\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2778 - val_loss: 0.3276\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2834 - val_loss: 0.3267\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2773 - val_loss: 0.3298\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2738 - val_loss: 0.3259\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2858 - val_loss: 0.3253\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2756 - val_loss: 0.3357\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2729 - val_loss: 0.3326\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2794 - val_loss: 0.3321\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2559 - val_loss: 0.3205\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2781 - val_loss: 0.3218\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2769 - val_loss: 0.3257\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2787 - val_loss: 0.3251\n",
      "121/121 [==============================] - 0s 902us/step - loss: 0.3110\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.6790 - val_loss: 0.7055\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6455 - val_loss: 0.6472\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5803 - val_loss: 0.6007\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5283 - val_loss: 0.5662\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5248 - val_loss: 0.5418\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4812 - val_loss: 0.5229\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4926 - val_loss: 0.5082\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4873 - val_loss: 0.4937\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4664 - val_loss: 0.4852\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4287 - val_loss: 0.4776\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4535 - val_loss: 0.4689\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4393 - val_loss: 0.4619\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 0.4595\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.4506\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4234 - val_loss: 0.4474\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3943 - val_loss: 0.4398\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.4356\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3877 - val_loss: 0.4333\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4019 - val_loss: 0.4314\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3976 - val_loss: 0.4269\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3838 - val_loss: 0.4209\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3673 - val_loss: 0.4197\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3770 - val_loss: 0.4120\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3808 - val_loss: 0.4090\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3728 - val_loss: 0.4065\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.4027\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.4020\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3720 - val_loss: 0.3996\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3796 - val_loss: 0.4042\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3778 - val_loss: 0.3950\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3528 - val_loss: 0.3952\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3462 - val_loss: 0.3883\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3480 - val_loss: 0.3860\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3363 - val_loss: 0.3843\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3357 - val_loss: 0.3836\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3391 - val_loss: 0.3810\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3401 - val_loss: 0.3788\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3365 - val_loss: 0.3771\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3225 - val_loss: 0.3748\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3230 - val_loss: 0.3818\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3406 - val_loss: 0.3743\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3285 - val_loss: 0.3833\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3209 - val_loss: 0.3710\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3358 - val_loss: 0.3674\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3276 - val_loss: 0.3670\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3145 - val_loss: 0.3655\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3084 - val_loss: 0.3629\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3239 - val_loss: 0.3653\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3119 - val_loss: 0.3608\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3121 - val_loss: 0.3757\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3192 - val_loss: 0.3670\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3138 - val_loss: 0.3584\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3198 - val_loss: 0.3573\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3114 - val_loss: 0.3570\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3196 - val_loss: 0.3656\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3119 - val_loss: 0.3555\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3046 - val_loss: 0.3569\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2920 - val_loss: 0.3572\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3000 - val_loss: 0.3597\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3077 - val_loss: 0.3496\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2915 - val_loss: 0.3563\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3088 - val_loss: 0.3553\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3021 - val_loss: 0.3528\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2987 - val_loss: 0.3483\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2997 - val_loss: 0.3476\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3145 - val_loss: 0.3569\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2989 - val_loss: 0.3473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3128 - val_loss: 0.3599\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3109 - val_loss: 0.3459\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3037 - val_loss: 0.3481\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2882 - val_loss: 0.3443\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3015 - val_loss: 0.3481\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2843 - val_loss: 0.3488\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3034 - val_loss: 0.3421\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.2917 - val_loss: 0.3460\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3019 - val_loss: 0.3460\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2814 - val_loss: 0.3482\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3178 - val_loss: 0.3420\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2891 - val_loss: 0.3407\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2989 - val_loss: 0.3471\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2866 - val_loss: 0.3420\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3011 - val_loss: 0.3372\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2918 - val_loss: 0.3395\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2941 - val_loss: 0.3519\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2932 - val_loss: 0.3408\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2882 - val_loss: 0.3504\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2891 - val_loss: 0.3356\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2821 - val_loss: 0.3470\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2896 - val_loss: 0.3356\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2956 - val_loss: 0.3414\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3013 - val_loss: 0.3414\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2790 - val_loss: 0.3494\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2901 - val_loss: 0.3495\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2782 - val_loss: 0.3344\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2824 - val_loss: 0.3392\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2927 - val_loss: 0.3369\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2804 - val_loss: 0.3384\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2955 - val_loss: 0.3553\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2797 - val_loss: 0.3473\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.2913 - val_loss: 0.3391\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3274\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.1017 - val_loss: 0.5544\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5848 - val_loss: 0.5485\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5389 - val_loss: 0.5518\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5470 - val_loss: 0.5422\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5203 - val_loss: 0.5600\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5457 - val_loss: 0.5485\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5462 - val_loss: 0.5525\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5442 - val_loss: 0.5462\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5535 - val_loss: 0.5518\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5302 - val_loss: 0.5393\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5464 - val_loss: 0.6462\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5477 - val_loss: 0.6013\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5723 - val_loss: 0.5448\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5381 - val_loss: 0.5483\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5806 - val_loss: 0.5463\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5441 - val_loss: 0.5475\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5871 - val_loss: 0.5548\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5133 - val_loss: 0.5940\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5374 - val_loss: 0.7310\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5599 - val_loss: 0.5425\n",
      "121/121 [==============================] - 0s 913us/step - loss: 0.5038\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.9544 - val_loss: 0.9331\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 67.6876 - val_loss: 6.1037\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 27.91 - 0s 1ms/step - loss: 256.8754 - val_loss: 370.8859\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 77657.3037 - val_loss: 13763.2344\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5855939.3254 - val_loss: 628416.3125\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 28595302.7097 - val_loss: 32136000.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 578894713.048 - 0s 1ms/step - loss: 1491482897.2840 - val_loss: 1518273792.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 79086227037.2346 - val_loss: 76738404352.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 9991059319466.6660 - val_loss: 2686012882944.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 441237166271146.6875 - val_loss: 121670576635904.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9567731868000492.0000 - val_loss: 5752438678093824.0000\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 954437253243863040.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.3425 - val_loss: 0.6406\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3192 - val_loss: 0.5284\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 206.4176 - val_loss: 1.3874\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 58.2017 - val_loss: 1.9310\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 143.9775 - val_loss: 9.5921\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 22517.7384 - val_loss: 78.5841\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9782.2623 - val_loss: 397.2953\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 21077.1085 - val_loss: 379.0616\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 758002.1976 - val_loss: 3782.5667\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 77341.5258 - val_loss: 5813.6665\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2115784.5803 - val_loss: 20740.6035\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 61659654.5856 - val_loss: 744860.9375\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 951649.1250\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.6886 - val_loss: 1.2257\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1042 - val_loss: 0.8297\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7835 - val_loss: 0.7682\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7149 - val_loss: 0.7346\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6950 - val_loss: 0.7073\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6599 - val_loss: 0.6848\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6564 - val_loss: 0.6654\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6150 - val_loss: 0.6476\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6052 - val_loss: 0.6329\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5862 - val_loss: 0.6190\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5928 - val_loss: 0.6071\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5632 - val_loss: 0.5967\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5694 - val_loss: 0.5868\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5390 - val_loss: 0.5786\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5693 - val_loss: 0.5706\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5197 - val_loss: 0.5634\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5296 - val_loss: 0.5575\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5376 - val_loss: 0.5515\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5157 - val_loss: 0.5464\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4957 - val_loss: 0.5415\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5228 - val_loss: 0.5370\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5076 - val_loss: 0.5342\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5032 - val_loss: 0.5299\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5020 - val_loss: 0.5261\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5005 - val_loss: 0.5225\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5192\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4943 - val_loss: 0.5177\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5097 - val_loss: 0.5146\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4851 - val_loss: 0.5125\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5071 - val_loss: 0.5099\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4857 - val_loss: 0.5090\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4838 - val_loss: 0.5056\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4752 - val_loss: 0.5045\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5018 - val_loss: 0.5019\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.4999\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4652 - val_loss: 0.4986\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4671 - val_loss: 0.4976\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4966 - val_loss: 0.4953\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4984 - val_loss: 0.4948\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4311 - val_loss: 0.4918\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4875 - val_loss: 0.4915\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4825 - val_loss: 0.4891\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4655 - val_loss: 0.4880\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4636 - val_loss: 0.4861\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.4850\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4601 - val_loss: 0.4837\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4753 - val_loss: 0.4826\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4747 - val_loss: 0.4812\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4639 - val_loss: 0.4799\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4431 - val_loss: 0.4789\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4369 - val_loss: 0.4776\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 0.4772\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4440 - val_loss: 0.4758\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4577 - val_loss: 0.4749\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.4738\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4565 - val_loss: 0.4730\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4460 - val_loss: 0.4716\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4380 - val_loss: 0.4710\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4412 - val_loss: 0.4705\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4320 - val_loss: 0.4693\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4677 - val_loss: 0.4684\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4435 - val_loss: 0.4680\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4440 - val_loss: 0.4670\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4451 - val_loss: 0.4663\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4413 - val_loss: 0.4654\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4267 - val_loss: 0.4650\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4489 - val_loss: 0.4640\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4373 - val_loss: 0.4634\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4561 - val_loss: 0.4628\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4351 - val_loss: 0.4623\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4410 - val_loss: 0.4612\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4201 - val_loss: 0.4608\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4360 - val_loss: 0.4601\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4411 - val_loss: 0.4595\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4324 - val_loss: 0.4587\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4545 - val_loss: 0.4582\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4526 - val_loss: 0.4581\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4347 - val_loss: 0.4568\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.4566\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4447 - val_loss: 0.4562\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4440 - val_loss: 0.4556\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4071 - val_loss: 0.4545\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4576 - val_loss: 0.4542\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4356 - val_loss: 0.4535\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4370 - val_loss: 0.4529\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4386 - val_loss: 0.4529\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4418 - val_loss: 0.4520\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4164 - val_loss: 0.4513\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 0.4508\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4404 - val_loss: 0.4504\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.4504\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.4499\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.4489\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4244 - val_loss: 0.4482\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4355 - val_loss: 0.4481\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4208 - val_loss: 0.4475\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4207 - val_loss: 0.4470\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4446 - val_loss: 0.4466\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4222 - val_loss: 0.4459\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4224 - val_loss: 0.4455\n",
      "121/121 [==============================] - 0s 896us/step - loss: 0.4085\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.8753 - val_loss: 1.2808\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0777 - val_loss: 0.8325\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7621 - val_loss: 0.7605\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7335 - val_loss: 0.7287\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6777 - val_loss: 0.7043\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6368 - val_loss: 0.6829\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6072 - val_loss: 0.6638\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5946 - val_loss: 0.6472\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6003 - val_loss: 0.6324\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5752 - val_loss: 0.6192\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5486 - val_loss: 0.6073\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5439 - val_loss: 0.5971\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5460 - val_loss: 0.5875\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5399 - val_loss: 0.5792\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5340 - val_loss: 0.5718\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5212 - val_loss: 0.5646\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5210 - val_loss: 0.5580\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5352 - val_loss: 0.5522\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5192 - val_loss: 0.5472\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5199 - val_loss: 0.5422\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.5377\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5058 - val_loss: 0.5334\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4779 - val_loss: 0.5293\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5144 - val_loss: 0.5260\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4948 - val_loss: 0.5227\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4954 - val_loss: 0.5200\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.5165\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4762 - val_loss: 0.5140\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4795 - val_loss: 0.5118\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.5087\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4871 - val_loss: 0.5068\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4720 - val_loss: 0.5041\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4669 - val_loss: 0.5019\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4453 - val_loss: 0.4999\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4512 - val_loss: 0.4985\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.4965\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4746 - val_loss: 0.4953\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4714 - val_loss: 0.4933\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4487 - val_loss: 0.4918\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4643 - val_loss: 0.4906\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4551 - val_loss: 0.4888\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.4877\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4582 - val_loss: 0.4868\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4644 - val_loss: 0.4851\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4560 - val_loss: 0.4836\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4452 - val_loss: 0.4823\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4656 - val_loss: 0.4819\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4447 - val_loss: 0.4801\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.4794\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.4783\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4500 - val_loss: 0.4772\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4318 - val_loss: 0.4758\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4722 - val_loss: 0.4751\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4213 - val_loss: 0.4739\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4632 - val_loss: 0.4731\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.4721\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4541 - val_loss: 0.4711\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4507 - val_loss: 0.4701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4262 - val_loss: 0.4692\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4489 - val_loss: 0.4684\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4312 - val_loss: 0.4676\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4348 - val_loss: 0.4668\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4386 - val_loss: 0.4661\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4343 - val_loss: 0.4652\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4387 - val_loss: 0.4645\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4291 - val_loss: 0.4634\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4302 - val_loss: 0.4632\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4136 - val_loss: 0.4622\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4461 - val_loss: 0.4615\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4313 - val_loss: 0.4605\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4379 - val_loss: 0.4600\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4331 - val_loss: 0.4588\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4322 - val_loss: 0.4584\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4293 - val_loss: 0.4580\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4201 - val_loss: 0.4572\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4211 - val_loss: 0.4563\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4232 - val_loss: 0.4556\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4217 - val_loss: 0.4553\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4298 - val_loss: 0.4543\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4213 - val_loss: 0.4536\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4316 - val_loss: 0.4531\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4069 - val_loss: 0.4525\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4338 - val_loss: 0.4520\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4271 - val_loss: 0.4513\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4247 - val_loss: 0.4507\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4376 - val_loss: 0.4501\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4417 - val_loss: 0.4495\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.4486\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4414 - val_loss: 0.4482\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4070 - val_loss: 0.4476\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4254 - val_loss: 0.4470\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3982 - val_loss: 0.4463\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4175 - val_loss: 0.4459\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3990 - val_loss: 0.4454\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4366 - val_loss: 0.4447\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4012 - val_loss: 0.4442\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4242 - val_loss: 0.4439\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4263 - val_loss: 0.4435\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4313 - val_loss: 0.4430\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4218 - val_loss: 0.4425\n",
      "121/121 [==============================] - 0s 885us/step - loss: 0.4299\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.3799 - val_loss: 1.1744\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0010 - val_loss: 0.8175\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.7789 - val_loss: 0.7575\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6815 - val_loss: 0.7291\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6407 - val_loss: 0.7063\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6434 - val_loss: 0.6867\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6217 - val_loss: 0.6685\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6201 - val_loss: 0.6516\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5719 - val_loss: 0.6366\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5852 - val_loss: 0.6230\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5742 - val_loss: 0.6112\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5553 - val_loss: 0.6010\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5590 - val_loss: 0.5905\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5602 - val_loss: 0.5811\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5506 - val_loss: 0.5737\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5408 - val_loss: 0.5660\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5400 - val_loss: 0.5595\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5091 - val_loss: 0.5533\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 0.5483\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5028 - val_loss: 0.5434\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4811 - val_loss: 0.5385\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5037 - val_loss: 0.5341\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4911 - val_loss: 0.5306\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5027 - val_loss: 0.5265\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4905 - val_loss: 0.5234\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4725 - val_loss: 0.5205\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4729 - val_loss: 0.5171\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4901 - val_loss: 0.5147\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4732 - val_loss: 0.5122\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4654 - val_loss: 0.5096\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4874 - val_loss: 0.5075\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4674 - val_loss: 0.5049\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4610 - val_loss: 0.5031\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4787 - val_loss: 0.5011\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4760 - val_loss: 0.4994\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4778 - val_loss: 0.4974\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.4956\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4926 - val_loss: 0.4943\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4528 - val_loss: 0.4923\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4555 - val_loss: 0.4911\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4666 - val_loss: 0.4892\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4478 - val_loss: 0.4882\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4451 - val_loss: 0.4867\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4738 - val_loss: 0.4857\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4594 - val_loss: 0.4841\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4385 - val_loss: 0.4829\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4530 - val_loss: 0.4813\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4581 - val_loss: 0.4804\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4653 - val_loss: 0.4794\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4328 - val_loss: 0.4781\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4353 - val_loss: 0.4768\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4526 - val_loss: 0.4760\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4517 - val_loss: 0.4750\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4672 - val_loss: 0.4743\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4593 - val_loss: 0.4733\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4382 - val_loss: 0.4721\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4315 - val_loss: 0.4712\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4263 - val_loss: 0.4703\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4591 - val_loss: 0.4690\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4291 - val_loss: 0.4684\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4265 - val_loss: 0.4676\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4372 - val_loss: 0.4670\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4243 - val_loss: 0.4659\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4303 - val_loss: 0.4653\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.4643\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4333 - val_loss: 0.4640\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4178 - val_loss: 0.4626\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4114 - val_loss: 0.4622\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4268 - val_loss: 0.4612\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4228 - val_loss: 0.4604\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.4599\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4201 - val_loss: 0.4590\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4187 - val_loss: 0.4587\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4405 - val_loss: 0.4578\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4158 - val_loss: 0.4576\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4191 - val_loss: 0.4569\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 0.4560\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4311 - val_loss: 0.4553\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4011 - val_loss: 0.4546\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4058 - val_loss: 0.4539\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4158 - val_loss: 0.4535\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4175 - val_loss: 0.4531\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4128 - val_loss: 0.4523\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4063 - val_loss: 0.4516\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.4514\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4209 - val_loss: 0.4504\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4158 - val_loss: 0.4498\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4123 - val_loss: 0.4495\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4095 - val_loss: 0.4488\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4076 - val_loss: 0.4481\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4333 - val_loss: 0.4482\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.4475\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4108 - val_loss: 0.4471\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 0.4466\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.4175 - val_loss: 0.4462\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3928 - val_loss: 0.4457\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4253 - val_loss: 0.4448\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4158 - val_loss: 0.4445\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4077 - val_loss: 0.4443\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4031 - val_loss: 0.4434\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.4314\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.4035 - val_loss: 1.5478\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2627 - val_loss: 0.7087\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6562 - val_loss: 0.5903\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5550 - val_loss: 0.5707\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5450 - val_loss: 0.5654\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5713 - val_loss: 0.5629\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5280 - val_loss: 0.5610\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5193 - val_loss: 0.5590\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5533 - val_loss: 0.5577\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5403 - val_loss: 0.5557\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5370 - val_loss: 0.5552\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5356 - val_loss: 0.5529\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5272 - val_loss: 0.5527\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5268 - val_loss: 0.5514\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5366 - val_loss: 0.5510\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5357 - val_loss: 0.5499\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5357 - val_loss: 0.5504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5378 - val_loss: 0.5490\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5412 - val_loss: 0.5524\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5337 - val_loss: 0.5495\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5503 - val_loss: 0.5476\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5208 - val_loss: 0.5485\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5198 - val_loss: 0.5470\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5343 - val_loss: 0.5477\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5360 - val_loss: 0.5468\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5277 - val_loss: 0.5463\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5280 - val_loss: 0.5488\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5298 - val_loss: 0.5515\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5205 - val_loss: 0.5484\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5471 - val_loss: 0.5462\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5241 - val_loss: 0.5466\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 0.5470\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5345 - val_loss: 0.5506\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5409 - val_loss: 0.5498\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5149 - val_loss: 0.5517\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5421 - val_loss: 0.5498\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5540 - val_loss: 0.5460\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5368 - val_loss: 0.5492\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 0.5499\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5149 - val_loss: 0.5534\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5318 - val_loss: 0.5480\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5254 - val_loss: 0.5466\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5224 - val_loss: 0.5468\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5234 - val_loss: 0.5468\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5261 - val_loss: 0.5484\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5370 - val_loss: 0.5460\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5237 - val_loss: 0.5469\n",
      "121/121 [==============================] - 0s 987us/step - loss: 0.5049\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 5.5630 - val_loss: 1.5088\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1747 - val_loss: 0.7100\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6280 - val_loss: 0.6023\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5717 - val_loss: 0.5832\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5416 - val_loss: 0.5763\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5498 - val_loss: 0.5717\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5413 - val_loss: 0.5678\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5223 - val_loss: 0.5649\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5274 - val_loss: 0.5619\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5223 - val_loss: 0.5610\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5001 - val_loss: 0.5595\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5261 - val_loss: 0.5588\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5371 - val_loss: 0.5569\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5490 - val_loss: 0.5552\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5005 - val_loss: 0.5544\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5142 - val_loss: 0.5527\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5144 - val_loss: 0.5511\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5247 - val_loss: 0.5532\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5261 - val_loss: 0.5509\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5312 - val_loss: 0.5498\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5297 - val_loss: 0.5486\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5278 - val_loss: 0.5483\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5064 - val_loss: 0.5487\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5021 - val_loss: 0.5510\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 0.5481\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5208 - val_loss: 0.5469\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5014 - val_loss: 0.5514\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5000 - val_loss: 0.5477\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5002 - val_loss: 0.5470\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5352 - val_loss: 0.5471\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5078 - val_loss: 0.5459\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5167 - val_loss: 0.5507\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5157 - val_loss: 0.5484\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5079 - val_loss: 0.5515\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5209 - val_loss: 0.5484\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5168 - val_loss: 0.5478\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5206 - val_loss: 0.5466\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5442 - val_loss: 0.5510\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5350 - val_loss: 0.5528\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5127 - val_loss: 0.5485\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5258 - val_loss: 0.5465\n",
      "121/121 [==============================] - 0s 865us/step - loss: 0.5289\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.0889 - val_loss: 1.4909\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1465 - val_loss: 0.8319\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7803 - val_loss: 0.7188\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6587 - val_loss: 0.6833\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6488 - val_loss: 0.6620\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6119 - val_loss: 0.6455\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6021 - val_loss: 0.6316\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6195\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5960 - val_loss: 0.6096\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5778 - val_loss: 0.6007\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6007 - val_loss: 0.5932\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5591 - val_loss: 0.5864\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5356 - val_loss: 0.5808\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5585 - val_loss: 0.5762\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5498 - val_loss: 0.5715\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5228 - val_loss: 0.5677\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5441 - val_loss: 0.5643\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5410 - val_loss: 0.5617\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5490 - val_loss: 0.5592\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5197 - val_loss: 0.5572\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5148 - val_loss: 0.5554\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5303 - val_loss: 0.5539\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5122 - val_loss: 0.5531\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5209 - val_loss: 0.5511\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5352 - val_loss: 0.5505\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5380 - val_loss: 0.5494\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4947 - val_loss: 0.5486\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5181 - val_loss: 0.5478\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5003 - val_loss: 0.5467\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5179 - val_loss: 0.5469\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5106 - val_loss: 0.5467\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5260 - val_loss: 0.5460\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5191 - val_loss: 0.5455\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5224 - val_loss: 0.5456\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5172 - val_loss: 0.5448\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5168 - val_loss: 0.5444\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5193 - val_loss: 0.5452\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5169 - val_loss: 0.5449\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5040 - val_loss: 0.5442\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5214 - val_loss: 0.5445\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5266 - val_loss: 0.5442\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5299 - val_loss: 0.5447\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5050 - val_loss: 0.5451\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5203 - val_loss: 0.5443\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4932 - val_loss: 0.5432\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5213 - val_loss: 0.5435\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5242 - val_loss: 0.5438\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5182 - val_loss: 0.5440\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5135 - val_loss: 0.5436\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5231 - val_loss: 0.5440\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5458 - val_loss: 0.5441\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5022 - val_loss: 0.5439\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5030 - val_loss: 0.5430\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5316 - val_loss: 0.5430\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5095 - val_loss: 0.5436\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5212 - val_loss: 0.5435\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5088 - val_loss: 0.5431\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5185 - val_loss: 0.5428\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5343 - val_loss: 0.5421\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5038 - val_loss: 0.5427\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5207 - val_loss: 0.5421\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5154 - val_loss: 0.5423\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5031 - val_loss: 0.5420\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5166 - val_loss: 0.5428\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5059 - val_loss: 0.5433\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5173 - val_loss: 0.5424\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5193 - val_loss: 0.5429\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4914 - val_loss: 0.5428\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5100 - val_loss: 0.5428\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5187 - val_loss: 0.5430\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5103 - val_loss: 0.5428\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4907 - val_loss: 0.5428\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5333 - val_loss: 0.5433\n",
      "121/121 [==============================] - 0s 855us/step - loss: 0.5383\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7371 - val_loss: 0.7018\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6305 - val_loss: 0.6107\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5682 - val_loss: 0.5611\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5700 - val_loss: 0.5412\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5116 - val_loss: 0.5240\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5078 - val_loss: 0.5099\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4905 - val_loss: 0.5014\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4841 - val_loss: 0.4937\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4854 - val_loss: 0.4879\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4741 - val_loss: 0.4923\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4734 - val_loss: 0.4784\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4724 - val_loss: 0.4772\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4459 - val_loss: 0.4739\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4432 - val_loss: 0.4725\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4645 - val_loss: 0.4686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4489 - val_loss: 0.4659\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4472 - val_loss: 0.4643\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4549 - val_loss: 0.4627\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4423 - val_loss: 0.4606\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4389 - val_loss: 0.4580\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4526 - val_loss: 0.4576\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4380 - val_loss: 0.4551\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4239 - val_loss: 0.4514\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4106 - val_loss: 0.4504\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4413 - val_loss: 0.4467\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4201 - val_loss: 0.4446\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4363 - val_loss: 0.4490\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4240 - val_loss: 0.4734\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4729 - val_loss: 0.4418\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4382 - val_loss: 0.4440\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 0.4397\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4193 - val_loss: 0.4336\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4213 - val_loss: 0.4411\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4130 - val_loss: 0.4301\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4175 - val_loss: 0.4280\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4103 - val_loss: 0.4301\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 0.4439\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4177 - val_loss: 0.4219\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3917 - val_loss: 0.4219\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3900 - val_loss: 0.4224\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.4207\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4219 - val_loss: 0.4192\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3871 - val_loss: 0.4206\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4009 - val_loss: 0.4156\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4057 - val_loss: 0.4183\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 0.4190\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4033 - val_loss: 0.4122\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4098 - val_loss: 0.4108\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3832 - val_loss: 0.4092\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.4101\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3951 - val_loss: 0.4090\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3996 - val_loss: 0.4044\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.4047\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3915 - val_loss: 0.4061\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3810 - val_loss: 0.4039\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3921 - val_loss: 0.4035\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3906 - val_loss: 0.3998\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3942 - val_loss: 0.3976\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.3972\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3878 - val_loss: 0.3979\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.3955\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3883 - val_loss: 0.3957\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3765 - val_loss: 0.3922\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3920 - val_loss: 0.3925\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3963 - val_loss: 0.3921\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3907\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.3931\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3645 - val_loss: 0.4042\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3913 - val_loss: 0.3877\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3785 - val_loss: 0.3874\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3682 - val_loss: 0.3889\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3916 - val_loss: 0.3886\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3892 - val_loss: 0.3861\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4306 - val_loss: 0.3848\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3650 - val_loss: 0.4808\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9405 - val_loss: 0.3886\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.3861\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3736 - val_loss: 0.4039\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4877 - val_loss: 0.3860\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.3870\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3747 - val_loss: 0.3852\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3698 - val_loss: 0.3825\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.3851\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3781 - val_loss: 0.3832\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3788 - val_loss: 0.3827\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3786 - val_loss: 0.3806\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3626 - val_loss: 0.3793\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3572 - val_loss: 0.3806\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3423 - val_loss: 0.3767\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3515 - val_loss: 0.3759\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.3784\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3548 - val_loss: 0.3781\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3644 - val_loss: 0.3756\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3396 - val_loss: 0.3811\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3481 - val_loss: 0.3747\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3488 - val_loss: 0.3780\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3614 - val_loss: 0.3731\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3688 - val_loss: 0.3757\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3356 - val_loss: 0.3742\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3581 - val_loss: 0.3715\n",
      "121/121 [==============================] - 0s 834us/step - loss: 0.3373\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.2469 - val_loss: 0.7509\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7282 - val_loss: 0.6824\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6161 - val_loss: 0.6155\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5410 - val_loss: 0.5824\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5407 - val_loss: 0.5617\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5155 - val_loss: 0.5428\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5081 - val_loss: 0.5278\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4660 - val_loss: 0.5143\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4924 - val_loss: 0.5041\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4842 - val_loss: 0.4960\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4356 - val_loss: 0.4865\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.4832\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4527 - val_loss: 0.4765\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4428 - val_loss: 0.4773\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4493 - val_loss: 0.4698\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4480 - val_loss: 0.4656\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4373 - val_loss: 0.4669\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4131 - val_loss: 0.4635\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4297 - val_loss: 0.4578\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4285 - val_loss: 0.4542\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4257 - val_loss: 0.4569\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4237 - val_loss: 0.4497\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4170 - val_loss: 0.4484\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4133 - val_loss: 0.4482\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4056 - val_loss: 0.4456\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.4417\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4345 - val_loss: 0.4395\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4116 - val_loss: 0.4370\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.4355\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.4348\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4004 - val_loss: 0.4325\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4095 - val_loss: 0.4308\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3978 - val_loss: 0.4290\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4186 - val_loss: 0.4270\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4257\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4012 - val_loss: 0.4239\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3927 - val_loss: 0.4233\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3846 - val_loss: 0.4242\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4026 - val_loss: 0.4200\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3891 - val_loss: 0.4187\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3884 - val_loss: 0.4200\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4014 - val_loss: 0.4169\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4030 - val_loss: 0.4148\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.4145\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3930 - val_loss: 0.4125\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 0.4131\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3676 - val_loss: 0.4117\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4029 - val_loss: 0.4087\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.4103\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4073\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3781 - val_loss: 0.4065\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.4049\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3847 - val_loss: 0.4066\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.4229\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3869 - val_loss: 0.4042\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3824 - val_loss: 0.4023\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3873 - val_loss: 0.4001\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3863 - val_loss: 0.4031\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.3998\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3767 - val_loss: 0.3998\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3512 - val_loss: 0.3994\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3611 - val_loss: 0.3987\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3572 - val_loss: 0.3959\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.3955\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3619 - val_loss: 0.3976\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3746 - val_loss: 0.3927\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3674 - val_loss: 0.3944\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3744 - val_loss: 0.3928\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3799 - val_loss: 0.3906\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3731 - val_loss: 0.3909\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3541 - val_loss: 0.3896\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3656 - val_loss: 0.3879\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3546 - val_loss: 0.3911\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3602 - val_loss: 0.3888\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.3876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3666 - val_loss: 0.3893\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.3868\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3546 - val_loss: 0.3860\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3636 - val_loss: 0.3866\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3791 - val_loss: 0.3852\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3574 - val_loss: 0.3850\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3638 - val_loss: 0.3824\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3594 - val_loss: 0.3819\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3672 - val_loss: 0.3964\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3636 - val_loss: 0.3825\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.3815\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.3818\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3637 - val_loss: 0.3797\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3601 - val_loss: 0.3793\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 0.3807\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3545 - val_loss: 0.3771\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3503 - val_loss: 0.3782\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3527 - val_loss: 0.3758\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3469 - val_loss: 0.3776\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3385 - val_loss: 0.3765\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3546 - val_loss: 0.3748\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3671 - val_loss: 0.3746\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3447 - val_loss: 0.3770\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3624 - val_loss: 0.3747\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3429 - val_loss: 0.3726\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.3593\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8387 - val_loss: 0.7360\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.6669 - val_loss: 0.6547\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5896 - val_loss: 0.6104\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5477 - val_loss: 0.5829\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.5239 - val_loss: 0.5586\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5093 - val_loss: 0.5445\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5244 - val_loss: 0.5274\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4629 - val_loss: 0.5145\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5637 - val_loss: 0.5071\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4786 - val_loss: 0.4994\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4761 - val_loss: 0.4981\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4583 - val_loss: 0.4874\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.4826\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4491 - val_loss: 0.4782\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4520 - val_loss: 0.4766\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.4694\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4417 - val_loss: 0.4664\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4467 - val_loss: 0.4630\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4073 - val_loss: 0.4586\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4110 - val_loss: 0.4584\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4147 - val_loss: 0.4554\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4118 - val_loss: 0.4522\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4219 - val_loss: 0.4516\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4284 - val_loss: 0.4481\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4100 - val_loss: 0.4456\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4169 - val_loss: 0.4426\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3943 - val_loss: 0.4416\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 0.4443\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 0.4395\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3976 - val_loss: 0.4359\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.4119 - val_loss: 0.4333\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3978 - val_loss: 0.4325\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3842 - val_loss: 0.4332\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3921 - val_loss: 0.4295\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3909 - val_loss: 0.4273\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3985 - val_loss: 0.4282\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3839 - val_loss: 0.4295\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3890 - val_loss: 0.4280\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 0.4225\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4212\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3849 - val_loss: 0.4221\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4196\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3939 - val_loss: 0.4201\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.4181\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3882 - val_loss: 0.4167\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3697 - val_loss: 0.4175\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3735 - val_loss: 0.4126\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3760 - val_loss: 0.4149\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3815 - val_loss: 0.4116\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3892 - val_loss: 0.4103\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3930 - val_loss: 0.4104\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3757 - val_loss: 0.4086\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3907 - val_loss: 0.4079\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3861 - val_loss: 0.4082\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3702 - val_loss: 0.4077\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.4057\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3711 - val_loss: 0.4062\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3600 - val_loss: 0.4048\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3536 - val_loss: 0.4046\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3790 - val_loss: 0.4026\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.4006\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 0.4009\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.4008\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3685 - val_loss: 0.3979\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3534 - val_loss: 0.3995\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.3985\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3496 - val_loss: 0.3963\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3628 - val_loss: 0.3957\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.3946\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3638 - val_loss: 0.3941\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3607 - val_loss: 0.3942\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3655 - val_loss: 0.3961\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3643 - val_loss: 0.3950\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3681 - val_loss: 0.3962\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.3910\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3538 - val_loss: 0.3912\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3407 - val_loss: 0.3895\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3684 - val_loss: 0.3905\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3513 - val_loss: 0.3912\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3460 - val_loss: 0.3916\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3650 - val_loss: 0.3863\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3518 - val_loss: 0.3974\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3537 - val_loss: 0.3863\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3469 - val_loss: 0.3854\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 0.3601 - val_loss: 0.3861\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3407 - val_loss: 0.3870\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3593 - val_loss: 0.3828\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3451 - val_loss: 0.3834\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3492 - val_loss: 0.3830\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3614 - val_loss: 0.3811\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3468 - val_loss: 0.3821\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3466 - val_loss: 0.3809\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3420 - val_loss: 0.3860\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3592 - val_loss: 0.3808\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3283 - val_loss: 0.3812\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3484 - val_loss: 0.3798\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3303 - val_loss: 0.3797\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3487 - val_loss: 0.3819\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3480 - val_loss: 0.3796\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.3525 - val_loss: 0.3755\n",
      "121/121 [==============================] - 0s 879us/step - loss: 0.3725\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x15a39cf10>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-44c4c24bfc53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrnd_search_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distribs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m rnd_search_cv.fit(X_train, y_train, epochs=100,\n\u001b[0m\u001b[1;32m      3\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0;31m# we clone again after setting params in case some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[1;32m    877\u001b[0m                 **self.best_params_))\n\u001b[1;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[1;32m     86\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                                (estimator, name))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x15a39cf10>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "uniform-neighborhood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0035921799962015176, 'n_hidden': 3, 'n_neurons': 36}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "electric-brighton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.31351269284884137"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "solid-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.estimator.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-welding",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "#### 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "unable-danish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 19s 2us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "finite-bleeding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "impaired-barbados",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "amber-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "passive-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "attractive-sperm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "alike-stanford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 28, 28)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "worthy-northwest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "invalid-metallic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(y_train[index], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "noted-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "imposed-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "vocal-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "athletic-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "expon_lr = ExponentialLearningRate(factor=1.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "satellite-michael",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 10s 5ms/step - loss: nan - accuracy: 0.4944 - val_loss: nan - val_accuracy: 0.0958\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[expon_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "close-research",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "martial-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "early-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "rural-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=3e-1),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "organizational-celebrity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_mnist_logs/run_001'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_index = 1 # increment this at every run\n",
    "run_logdir = os.path.join(os.curdir, \"my_mnist_logs\", \"run_{:03d}\".format(run_index))\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "unlike-stewart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.4200 - accuracy: 0.8678 - val_loss: 0.0978 - val_accuracy: 0.9704\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.0943 - accuracy: 0.9696 - val_loss: 0.0885 - val_accuracy: 0.9744\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0656 - accuracy: 0.9782 - val_loss: 0.0836 - val_accuracy: 0.9764\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0441 - accuracy: 0.9852 - val_loss: 0.0721 - val_accuracy: 0.9806\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0359 - accuracy: 0.9885 - val_loss: 0.0773 - val_accuracy: 0.9812\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.0292 - accuracy: 0.9901 - val_loss: 0.0768 - val_accuracy: 0.9816\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0965 - val_accuracy: 0.9772\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0188 - accuracy: 0.9942 - val_loss: 0.0950 - val_accuracy: 0.9770\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 6s 3ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0786 - val_accuracy: 0.9834\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 0.0955 - val_accuracy: 0.9788\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0146 - accuracy: 0.9957 - val_loss: 0.0946 - val_accuracy: 0.9808\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 8s 5ms/step - loss: 0.0111 - accuracy: 0.9962 - val_loss: 0.1084 - val_accuracy: 0.9790\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.1064 - val_accuracy: 0.9790\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0908 - val_accuracy: 0.9826\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.1106 - val_accuracy: 0.9764\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0872 - val_accuracy: 0.9848\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 6s 4ms/step - loss: 3.4677e-04 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9848\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 1.0653e-04 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 0.9846\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 8.2754e-05 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9856\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 7.2407e-05 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9852\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 5.9861e-05 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9854\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 6.0550e-05 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9854\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 5.2415e-05 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9854\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 4.5223e-05 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9854\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "southern-spice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0781 - accuracy: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07812134176492691, 0.9775000214576721]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_mnist_model.h5\") # rollback to best model\n",
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
